{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern similarity analyses\n",
    "\n",
    "### Goals of this script\n",
    "Compute correlations between specific events of interest within a subject.  \n",
    "\n",
    "1. import labels (regressor files) for each run type (trimmed but not shifted)\n",
    "    - study runs\n",
    "    - familiarization runs\n",
    "    - reward runs\n",
    "    - postScenes\n",
    "    - postFaces\n",
    "2. shift labels to account for hemodynamic lag, concatenate run types, other cleanup\n",
    "3. load voxel x TR matrix for ROI(s) of interest\n",
    "4. extract patterns of interest and compute correlations: \n",
    "    - preA, postB (differentiation)\n",
    "    - preB, vioX & preB, vioY (B prediction during vio)\n",
    "    - postB, rewardA (5 repetitions, B prediction during reward)\n",
    "    - postB, postX & postB, postY\n",
    "5. Fisher z-transform r-values, average pairs within condition, compute difference between conditions, convert back to r\n",
    "6. 2nd order correlations:\n",
    "    - Correlate B prediction with differentiation for violation pairs\n",
    "    - Correlate postB,postXY value with differentiation in violation condition\n",
    "    - Correlate B prediction during reward learning with differentiation\n",
    "7. Randomization analyses:\n",
    "    - differentiation: scramble preApostB pairings, compute preApostB for scrambled pairs, Fisher z-transform, average pairs within condition, and compute different between conditions. Do this 1000x.\n",
    "    - B prediction during vio: scramble preBavgXY pairings, compute B prediction for scrambled pairs, correlate shuffled B prediction with original differentiation score in violation condition. Do this 1000x.\n",
    "    - For each variable, compute the z-score of the true value relative to the mean and SD of the permuted distribution. \n",
    "    - Save this subject's z-scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'sub-XXX'\n",
    "version = 'v4' #refers to version of the hippocampal masks\n",
    "binarization_thresh='50' #refers to hippocampal mask thresholding\n",
    "mask_list=['left_CA2+3+DG_1.5mm', 'right_CA2+3+DG_1.5mm', 'bilateral_CA2+3+DG_1.5mm',\n",
    "      'left_CA2+3_1.5mm', 'right_CA2+3_1.5mm', 'bilateral_CA2+3_1.5mm',\n",
    "      'left_DG_1.5mm', 'right_DG_1.5mm', 'bilateral_DG_1.5mm',\n",
    "      'left_CA1_1.5mm', 'right_CA1_1.5mm', 'bilateral_CA1_1.5mm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import nilearn\n",
    "from nilearn.input_data import NiftiMasker,  MultiNiftiMasker\n",
    "from nilearn.masking import intersect_masks\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "from nilearn.plotting import plot_roi\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io\n",
    "from mpi4py import MPI\n",
    "import os\n",
    "from os import path\n",
    "import pickle \n",
    "import time\n",
    "from scipy.sparse import random\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats.stats import pearsonr   \n",
    "from scipy.spatial.distance import euclidean\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import seaborn as sns\n",
    "#import plotly.express as px\n",
    "\n",
    "%matplotlib inline \n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print('The python version is {}.'.format(python_version()))\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "print('The nilearn version is {}.'.format(nilearn.__version__))\n",
    "print('The seaborn version is {}.'.format(sns.__version__))\n",
    "\n",
    "assert python_version()== '3.7.6'\n",
    "assert nilearn.__version__=='0.6.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set printing precision\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# load some helper functions\n",
    "sys.path.insert(0, '/jukebox/norman/emcdevitt/studies/SVD/code/mainanalysis')\n",
    "import svd_utils\n",
    "#from svd_utils import load_svd_epi_data, shift_timing, label2TR, mask_data\n",
    "\n",
    "# load some constants\n",
    "from svd_utils import n_runs, run_names, svd_TR, TRs_run\n",
    "\n",
    "# Parameters\n",
    "svd_hrf_lag = svd_TR*3\n",
    "n_trunc_beginning=9 #Number of volumes to trim from beginning of run\n",
    "n_trunc_end=5 #Number of volumes to trim from end of run\n",
    "\n",
    "# label dictionaries\n",
    "conditions = {1:\"vio\", 2:\"nonvio\", 3:\"vio-nonvio\"}\n",
    "groups = {0:\"wake\", 1:\"NREM\", 2:\"REM\"}\n",
    "categories = {0:\"rest\", 1:\"face\", 2:\"scene\", 3:\"object\"}\n",
    "scene_subcategories = {1:\"indoor\", 2:\"outdoor\"}\n",
    "face_subcategories = {1:\"female\", 2:\"male\"}\n",
    "pair_type = {1:\"outdoor/outdoor\", 2:\"indoor/indoor\", 3: \"indoor/outdoor\", 4: \"outdoor/indoor\"}\n",
    "reward_cond = {1:\"reward\", 2:\"neutral\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "svd_bids_dir = '/jukebox/norman/emcdevitt/studies/SVD/data/bids/Norman/McDevitt/7137_viodiff/' #fmri data\n",
    "behavioral_dir = '/jukebox/norman/emcdevitt/studies/SVD/data/behavioral/regressor/' #regressor files\n",
    "out_dir='/jukebox/norman/emcdevitt/studies/SVD/data/mainanalysis/output/notebook-05-pattern-similarity_%s_thresh-%s/' % (version, binarization_thresh) #folder where outputs of this notebook will be saved for each subject\n",
    "\n",
    "# make out_dir if it doesn't exist\n",
    "if os.path.exists(out_dir)==False:\n",
    "    print('making new directory: %s' %out_dir)\n",
    "    print('')\n",
    "    os.mkdir(out_dir) \n",
    "\n",
    "deriv_dir=svd_bids_dir + 'v1.2.3_derivatives/'\n",
    "preproc_dir=deriv_dir + 'fmriprep/%s/' % sub\n",
    "anat_dir=deriv_dir + 'deface/' #defaced T1w images\n",
    "mask_fold_other=deriv_dir + 'firstlevel/%s/masks/' % sub\n",
    "mask_fold_hipp=deriv_dir + 'firstlevel/%s/rois_ashs/t1space_%s/threshold-%s/' % (sub, version, binarization_thresh)\n",
    "epi_data_version='masked_epi_data_%s/threshold-%s' % (version, binarization_thresh)\n",
    "epi_dir= deriv_dir + 'firstlevel/%s/%s/' % (sub,epi_data_version)\n",
    "\n",
    "print('bids dir = %s' % (svd_bids_dir))\n",
    "print('')\n",
    "print('mask dir = %s' % (mask_fold_hipp))\n",
    "print('')\n",
    "print('epi data dir = %s' % (epi_dir))\n",
    "print('')\n",
    "print('output dir = %s' % (out_dir))\n",
    "print('')\n",
    "print('ROIs = %s' % (mask_list))\n",
    "print('')\n",
    "print('LIST OF ALL TASKS:', run_names)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running for subjects individually, check that necessary files exist for all subjects\n",
    "data used in this notebook: study-and-postscenes, postscenes, postfaces, familiarization, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_list = [104,105,106,107,108,109,110,111,112,114,115,116,117,119,120,122,125,126,127,129,132,133,134,135,137,139,140,141,\n",
    "#                142,143,144,145,146,147,148,149,150,151,152,153,155,156,158,159,160,161,162,164,165,166,168,169,170,172,173,174,175,\n",
    "#                176,177,178,179,180,181,182,184,185,186,187,188] \n",
    "# # excluded subjects: 123,128,130,136,167\n",
    "\n",
    "# n_subjects = len(subject_list)\n",
    "# print('n_subjects:', n_subjects)\n",
    "# print('')\n",
    "\n",
    "# def main(in_file,sub,mask):\n",
    "#     if path.exists(in_file)==False: #only prints if file doesn't exist\n",
    "#         print (sub+ ' '+mask+\" file exists: \"+str(path.exists(in_file)))\n",
    "\n",
    "# print('checking that all study-and-postscenes %s files exist' %epi_data_version)\n",
    "# for subject in range(0, n_subjects):\n",
    "#     this_sub = int(subject_list[subject])\n",
    "#     sub = 'sub-%s' % (this_sub)\n",
    "#     sub_dir= deriv_dir + 'firstlevel/%s/%s/' % (sub,epi_data_version)\n",
    "#     for mask_counter in range(len(mask_list)):\n",
    "#         this_mask = mask_list[mask_counter]\n",
    "#         in_file = (sub_dir + '%s_task-study-and-postscenes_run-ALL_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "#         if __name__== \"__main__\":\n",
    "#             main(in_file,sub,this_mask)\n",
    "# print('')\n",
    "\n",
    "# print('checking that all postscenes %s files exist' %epi_data_version)\n",
    "# for subject in range(0, n_subjects):\n",
    "#     this_sub = int(subject_list[subject])\n",
    "#     sub = 'sub-%s' % (this_sub)\n",
    "#     sub_dir= deriv_dir + 'firstlevel/%s/%s/' % (sub,epi_data_version)\n",
    "#     for mask_counter in range(len(mask_list)):\n",
    "#         this_mask = mask_list[mask_counter]\n",
    "#         in_file = (sub_dir + '%s_task-postscenes_run-01_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "#         if __name__== \"__main__\":\n",
    "#             main(in_file,sub,this_mask)\n",
    "# print('')\n",
    "\n",
    "# print('checking that all postfaces %s files exist' %epi_data_version)\n",
    "# for subject in range(0, n_subjects):\n",
    "#     this_sub = int(subject_list[subject])\n",
    "#     sub = 'sub-%s' % (this_sub)\n",
    "#     sub_dir= deriv_dir + 'firstlevel/%s/%s/' % (sub,epi_data_version)\n",
    "#     for mask_counter in range(len(mask_list)):\n",
    "#         this_mask = mask_list[mask_counter]\n",
    "#         in_file = (sub_dir + '%s_task-postfaces_run-01_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "#         if __name__== \"__main__\":\n",
    "#             main(in_file,sub,this_mask)\n",
    "# print('')\n",
    "\n",
    "# print('checking that all familiarization %s files exist' %epi_data_version)\n",
    "# for subject in range(0, n_subjects):\n",
    "#     this_sub = int(subject_list[subject])\n",
    "#     sub = 'sub-%s' % (this_sub)\n",
    "#     sub_dir= deriv_dir + 'firstlevel/%s/%s/' % (sub,epi_data_version)\n",
    "#     for mask_counter in range(len(mask_list)):\n",
    "#         this_mask = mask_list[mask_counter]\n",
    "#         in_file = (sub_dir + '%s_task-familiarization_run-ALL_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "#         if __name__== \"__main__\":\n",
    "#             main(in_file,sub,this_mask)\n",
    "# print('')\n",
    "\n",
    "# print('checking that all reward %s files exist' %epi_data_version)\n",
    "# for subject in range(0, n_subjects):\n",
    "#     this_sub = int(subject_list[subject])\n",
    "#     sub = 'sub-%s' % (this_sub)\n",
    "#     sub_dir= deriv_dir + 'firstlevel/%s/%s/' % (sub,epi_data_version)\n",
    "#     for mask_counter in range(len(mask_list)):\n",
    "#         this_mask = mask_list[mask_counter]\n",
    "#         in_file = (sub_dir + '%s_task-reward_run-ALL_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "#         if __name__== \"__main__\":\n",
    "#             main(in_file,sub,this_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load subject's T1w and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subject's defaced T1 image (merged T1 from fmriprep)\n",
    "t1_file = anat_dir + sub + '_desc-preproc_T1w_defaced.nii.gz'\n",
    "t1_img = image.load_img(t1_file) \n",
    "\n",
    "# Make a function to load the mask data\n",
    "def load_svd_mask(ROI_name, sub):\n",
    "    \"\"\"Load the mask for the svd data \n",
    "    Parameters\n",
    "    ----------\n",
    "    ROI_name: string\n",
    "    sub: string \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    the requested mask\n",
    "    \"\"\"    \n",
    "    # load the mask\n",
    "    if ROI_name == 'bilateral_oc-temp':\n",
    "        mask_fold=mask_fold_other\n",
    "    else:\n",
    "        mask_fold=mask_fold_hipp\n",
    "    maskfile = (mask_fold + sub + \"_%s.nii.gz\" % (ROI_name))\n",
    "    mask = nib.load(maskfile)\n",
    "    print(\"Loaded mask: %s\" % (ROI_name))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot this subject's ROIs\n",
    "for mask_counter in range(len(mask_list)):\n",
    "        this_mask = mask_list[mask_counter]\n",
    "        mask = load_svd_mask(mask_list[mask_counter], sub) # load the mask for the corresponding ROI\n",
    "        \n",
    "        # plot mask overlayed on subject's T1\n",
    "        plot_roi(mask, bg_img=t1_img, title=this_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study runs\n",
    "### Prep labels, load BOLD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study runs\n",
    "task = 'study'\n",
    "ses = 'ses-01'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_study = n_runs[task_index]\n",
    "TRs_run_study=TRs_run[task_index]-n_trunc_beginning-n_trunc_end\n",
    "print('TASK:', task)\n",
    "print('task index:', task_index)\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('TRs per run before trimming = %s' % (TRs_run[task_index]))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('TRs per run after trimming = %s' % (TRs_run_study))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load study regressor file\n",
    "/jukebox/norman/emcdevitt/studies/SVD/data/behavioral/regressor/task-study_regRow_reshaped.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_row_labels={'cond': 0, 'repetition': 1, 'pairID_orig': 2, 'ipi': 3, 'order': 4, 'subcategory': 5,\n",
    "                'category': 6, 'imgID': 7, 'learningBlk': 8, 'learningTrial': 9, 'time': 10,\n",
    "                'response': 11, 'rt': 12, 'accuracy': 13, 'tr_original': 14, 'tr_trimmed': 15,\n",
    "                'uniquePairID': 16, 'exposureNum': 17, 'index': 18, 'cond_orig': 19} #index and cond_orig rows to be added\n",
    "print(study_row_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stimulus labels from regressor file for each run and concatenate\n",
    "# NOTE: Regressor files are already trimmed (beginning only), but not shifted, in Matlab using gen_study_regressor_0101.m\n",
    "\n",
    "stim_label = []\n",
    "stim_label_allruns = []\n",
    "stim_label_allruns_shifted = []\n",
    "\n",
    "# take individual run regressor files and concatenate them\n",
    "for run in range(1, n_runs_study + 1):\n",
    "    in_file = (behavioral_dir + '%s_%s_task-%s_regressor-noshift-trim%dTRs-reshaped_run-0%d.mat' % (sub, ses, task, n_trunc_beginning, run))\n",
    "    \n",
    "    # Load in data from matlab and trim end of labels\n",
    "    stim_label = scipy.io.loadmat(in_file);\n",
    "    stim_label = np.array(stim_label['regressor']);\n",
    "    stim_label = stim_label[:,:-n_trunc_end] # trim label end\n",
    "\n",
    "    # Store the data\n",
    "    if run == 1:\n",
    "        stim_label_allruns = stim_label;\n",
    "    else:       \n",
    "        stim_label_allruns = np.hstack((stim_label_allruns, stim_label))\n",
    "\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('')\n",
    "print('Trimmed (but not shifted) labels should begin with 3-0-3-0 and end with 9 trailing zeros')\n",
    "print(stim_label_allruns[0,:21])\n",
    "print(stim_label_allruns[0,-20:])\n",
    "\n",
    "# Plot the labels\n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label_allruns[0,:], c='orange')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data labels to account for hemodynamic lag\n",
    "shift_size = int(svd_hrf_lag / svd_TR)  # Convert the shift into TRs\n",
    "print('shift by %s TRs' % (shift_size))\n",
    "\n",
    "zero_shift = np.zeros((np.shape(stim_label_allruns)[0],shift_size)) #columns to insert at beginning\n",
    "end_trim = np.shape(stim_label_allruns)[1]-shift_size #trim columns at the end\n",
    "\n",
    "# insert shift columns at beginning and trim columns at end\n",
    "stim_label_allruns_shifted = np.hstack((zero_shift,stim_label_allruns[:,0:end_trim])) \n",
    "\n",
    "# stim_label_allruns_shifted = shift_timing(stim_label_allruns[0,:], shift_size)\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('stim_label_allruns_shifted has shape: ', np.shape(stim_label_allruns_shifted))\n",
    "print('')\n",
    "print('Trimmed AND shifted labels should have 3 leading zeros and 6 trailing zeros')\n",
    "print(stim_label_allruns_shifted[0,:15])\n",
    "print(stim_label_allruns_shifted[0,-15:])\n",
    "\n",
    "# Plot the original and shifted labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(stim_label_allruns[0,:], label='original', c='orange')\n",
    "ax.plot(stim_label_allruns_shifted[0,:], label='shifted', c='blue')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index row\n",
    "index_list = np.arange(len(stim_label_allruns_shifted[1]))\n",
    "stim_label_allruns_shifted=np.vstack([stim_label_allruns_shifted, index_list])\n",
    "\n",
    "# copy original condition labels (prestudy=3) to bottom row\n",
    "stim_label_allruns_shifted=np.vstack([stim_label_allruns_shifted, stim_label_allruns_shifted[0,:]])\n",
    "\n",
    "print(stim_label_allruns_shifted[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update condition label for prelearning scenes (originally all prelearning scenes were coded as '3')\n",
    "\n",
    "print('uniquePairID, 1-48=cond1 and 49-96=cond2:')\n",
    "print(stim_label_allruns_shifted[study_row_labels['uniquePairID'],:15]) # IDs 1-48=cond1, 49-96=cond2\n",
    "print('')\n",
    "\n",
    "def numberfunc(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x > 48:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "recode_condition = np.array(list(map(numberfunc, stim_label_allruns_shifted[study_row_labels['uniquePairID'],])))\n",
    "stim_label_allruns_shifted[study_row_labels['cond'],:] = recode_condition\n",
    "\n",
    "print('original condition:', stim_label_allruns_shifted[study_row_labels['cond_orig'],:15])\n",
    "print('recoded condition:', recode_condition[:15])\n",
    "\n",
    "# Plot the vio/nonvio condition labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(stim_label_allruns_shifted[study_row_labels['cond_orig'],-50:], label='original', c='blue') # this row includes prelearning=3\n",
    "ax.plot(stim_label_allruns_shifted[study_row_labels['cond'],-50:], label='recoded', c='orange') # this row codes for vio or nonvio\n",
    "ax.set_ylabel('vio or nonvio')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that condition labels match for non-prelearning trials\n",
    "for x in range(len(stim_label_allruns_shifted[1])):\n",
    "    if stim_label_allruns_shifted[study_row_labels['cond_orig'],x] != 3:\n",
    "        assert stim_label_allruns_shifted[study_row_labels['cond_orig'],x] == stim_label_allruns_shifted[study_row_labels['cond'],x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename labels\n",
    "study_labels_shifted = stim_label_allruns_shifted\n",
    "print('study label list - shape:', study_labels_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Study voxel x TR BOLD data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load voxel x TR data for each ROI\n",
    "masked_data = []\n",
    "masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    # load the mask for the corresponding ROI\n",
    "    this_mask = mask_list[mask_counter]\n",
    "        \n",
    "    # Load in data from matlab\n",
    "    in_file = (epi_dir + '%s_task-study-and-postscenes_run-ALL_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "    masked_data = scipy.io.loadmat(in_file)\n",
    "    masked_data = np.array(masked_data['data'])\n",
    "    masked_data = masked_data[:,:-200] #remove postscenes timepoints\n",
    "    print(this_mask, masked_data.shape)\n",
    "    assert masked_data.shape[1] == study_labels_shifted.shape[1] #check that BOLD data and labels have same number of timepoints\n",
    "    masked_data_all[mask_counter] = masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of the data and plot value of voxel_id across timeseries; make sure data are z-scored \n",
    "num_voxels = [0] * len(mask_list)\n",
    "voxel_id = 10\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    num_voxels[mask_counter] = masked_data_all[mask_counter].shape[0] #save number of voxels in each mask\n",
    "    \n",
    "    f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "    ax.plot(masked_data_all[mask_counter][voxel_id,:])\n",
    "    ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (this_mask, voxel_id))\n",
    "    ax.set_xlabel('TR')\n",
    "    ax.set_ylabel('Voxel Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape BOLD data and rename\n",
    "bold_data=[]\n",
    "study_bold_data = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print(this_mask)\n",
    "        \n",
    "    # # Pull out the indexes\n",
    "    #indexed_data = masked_data_all[mask_counter][:,label_index] #this pulls out columns associated with non-zero labels in the epi data\n",
    "    \n",
    "    # transpose bold data to make it timepoints x n_voxels\n",
    "    bold_data = np.transpose(masked_data_all[mask_counter])\n",
    "    print('Original BOLD data shape:', masked_data_all[mask_counter].shape)\n",
    "    print('Transposed BOLD data shape:', bold_data.shape)\n",
    "    print('')\n",
    "\n",
    "    study_bold_data[mask_counter] = bold_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postscenes run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'postScenes'\n",
    "ses = 'ses-02'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_postscenes = n_runs[task_index]\n",
    "TRs_run_postscenes=TRs_run[task_index]-n_trunc_beginning-n_trunc_end\n",
    "print('TASK:', task)\n",
    "print('task index:', task_index)\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('TRs per run before trimming = %s' % (TRs_run[task_index]))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('TRs per run after trimming = %s' % (TRs_run_postscenes))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load postscenes regressor file\n",
    "/jukebox/norman/emcdevitt/studies/SVD/data/behavioral/regressor/task-postStudy_regRow_reshaped.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postscenes_row_labels={'cond': 0, 'repetition': 1, 'pairID_orig': 2, 'ipi': 3, 'order': 4, 'subcategory': 5,\n",
    "                'category': 6, 'imgID': 7, 'learningBlk': 8, 'learningTrial': 9, 'time': 10,\n",
    "                'response': 11, 'rt': 12, 'accuracy': 13, 'tr_original': 14, 'tr_trimmed': 15,\n",
    "                'uniquePairID': 16, 'exposureNum': 17, 'index': 18} #index row to be added\n",
    "print(postscenes_row_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Regressor files are already trimmed (beginning only), but not shifted, in Matlab using gen_study_regressor_0101.m\n",
    "stim_label = []\n",
    "stim_label_shifted = []\n",
    "\n",
    "in_file = (behavioral_dir + '%s_%s_task-%s_regressor-noshift-trim%dTRs-reshaped_run-01.mat' % (sub, ses, task, n_trunc_beginning))\n",
    "stim_label = scipy.io.loadmat(in_file) # Load in data from matlab\n",
    "stim_label = np.array(stim_label['regressor'])\n",
    "stim_label = stim_label[:,:-n_trunc_end] # trim label end\n",
    "\n",
    "print('stim_label has shape: ', np.shape(stim_label))\n",
    "print('')\n",
    "print('Trimmed (but not shifted) labels should begin with alternating 1s/2s and 0s and end with 9 trailing zeros')\n",
    "print(stim_label[0,:21])\n",
    "print(stim_label[0,-20:])\n",
    "\n",
    "# Plot the labels\n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label[0,:], c='orange')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data labels to account for hemodynamic lag\n",
    "shift_size = int(svd_hrf_lag / svd_TR)  # Convert the shift into TRs\n",
    "print('shift by %s TRs' % (shift_size))\n",
    "\n",
    "zero_shift = np.zeros((np.shape(stim_label)[0],shift_size)) #columns to insert at beginning\n",
    "end_trim = np.shape(stim_label)[1]-shift_size #trim columns at the end\n",
    "# insert shift columns at beginning and trim columns at end\n",
    "stim_label_shifted = np.hstack((zero_shift,stim_label[:,0:end_trim])) \n",
    "\n",
    "print('stim_label has shape: ', np.shape(stim_label))\n",
    "print('stim_label_shifted has shape: ', np.shape(stim_label_shifted))\n",
    "print('')\n",
    "print('Trimmed AND shifted labels should have 3 leading zeros and 6 trailing zeros')\n",
    "print(stim_label_shifted[0,:15])\n",
    "print(stim_label_shifted[0,-15:])\n",
    "\n",
    "# Plot the original and shifted labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(stim_label[0,:], label='original', c='orange')\n",
    "ax.plot(stim_label_shifted[0,:], label='shifted', c='blue')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index row\n",
    "index_list = np.arange(len(stim_label_shifted[1]))\n",
    "stim_label_shifted=np.vstack([stim_label_shifted, index_list])\n",
    "print(stim_label_shifted[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename labels\n",
    "postscenes_labels_shifted = stim_label_shifted\n",
    "print('label list - shape:', postscenes_labels_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Postscenes voxel x TR BOLD data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load voxel x TR data for each ROI\n",
    "masked_data = []\n",
    "masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    # load the mask for the corresponding ROI\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    # Load in data from matlab\n",
    "    in_file = (epi_dir + '%s_task-postscenes_run-01_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "    masked_data = scipy.io.loadmat(in_file)\n",
    "    masked_data = np.array(masked_data['data'])\n",
    "    assert masked_data.shape[1] == postscenes_labels_shifted.shape[1] #check that BOLD data and labels have same number \n",
    "    print(this_mask, masked_data.shape)\n",
    "    masked_data_all[mask_counter] = masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of the data and plot value of voxel_id across timeseries; make sure data are z-scored \n",
    "num_voxels = [0] * len(mask_list)\n",
    "voxel_id = 10\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    num_voxels[mask_counter] = masked_data_all[mask_counter].shape[0] #save number of voxels in each mask\n",
    "    \n",
    "    f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "    ax.plot(masked_data_all[mask_counter][voxel_id,:])\n",
    "    ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (this_mask, voxel_id))\n",
    "    ax.set_xlabel('TR')\n",
    "    ax.set_ylabel('Voxel Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape BOLD data and rename\n",
    "bold_data=[]\n",
    "postscenes_bold_data = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print(this_mask)\n",
    "    # transpose bold data to make it timepoints x n_voxels\n",
    "    bold_data = np.transpose(masked_data_all[mask_counter])\n",
    "    print('Original BOLD data shape:', masked_data_all[mask_counter].shape)\n",
    "    print('Transposed BOLD data shape:', bold_data.shape)\n",
    "    print('')\n",
    "\n",
    "    postscenes_bold_data[mask_counter] = bold_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Familiarization runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'familiarization'\n",
    "ses = 'ses-02'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_familiarization = n_runs[task_index]\n",
    "TRs_run_familiarization=TRs_run[task_index]-n_trunc_beginning-n_trunc_end\n",
    "print('TASK:', task)\n",
    "print('task index:', task_index)\n",
    "print('number of task runs:', n_runs_familiarization)\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('TRs per run before trimming = %s' % (TRs_run[task_index]))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('TRs per run after trimming = %s' % (TRs_run_familiarization))\n",
    "print('expected length of BOLD data series:', TRs_run_familiarization*n_runs_familiarization)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load familiarization regressor file\n",
    "row labels: '/jukebox/norman/emcdevitt/studies/SVD/data/behavioral/regressor/task-familiarization_regRow_all.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_row_labels={'cond': 0, 'repetition': 1, 'pairID_orig': 2, 'ipi': 3, 'order': 4, 'subcategory': 5,\n",
    "                'category': 6, 'imgID': 7, 'learningTrialOnset': 8, 'trialNum': 9, 'learningBlk': 10,\n",
    "                'index': 11, 'pairtype': 12, 'cycle': 13, 'rewardcond': 14, 'time': 15,\n",
    "                'response': 16, 'rt': 17, 'accuracy': 18, 'onsetOutcome': 19, 'recordedOutcome': 20,\n",
    "                'fMRItriggerOutcome': 21, 'run': 22, 'uniquePairID': 23, 'tr_original': 24, 'tr_trimmed': 25}\n",
    "print(fam_row_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stimulus labels from regressor file for each run and concatenate\n",
    "# NOTE: Regressor files are already trimmed (beginning only), but not shifted, in Matlab using gen_reward_regressor_0101.m\n",
    "\n",
    "stim_label = []\n",
    "stim_label_allruns = []\n",
    "stim_label_allruns_shifted = []\n",
    "\n",
    "# take individual run regressor files and concatenate them\n",
    "for run in range(1, n_runs_familiarization + 1):\n",
    "    in_file = (behavioral_dir + '%s_%s_task-%s_regressor-noshift-trim%dTRs_run-0%d.mat' % (sub, ses, task, n_trunc_beginning, run))\n",
    "    \n",
    "    # Load in data from matlab and trim end of labels\n",
    "    stim_label = scipy.io.loadmat(in_file);\n",
    "    stim_label = np.array(stim_label['regressor']);\n",
    "    stim_label = stim_label[:,:-n_trunc_end] # trim label end\n",
    "\n",
    "    # Store the data\n",
    "    if run == 1:\n",
    "        stim_label_allruns = stim_label;\n",
    "    else:       \n",
    "        stim_label_allruns = np.hstack((stim_label_allruns, stim_label))\n",
    "\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('')\n",
    "print('Trimmed (but not shifted) labels should begin with X-0-0-X-0-0-X and end with 10 trailing zeros')\n",
    "print(stim_label_allruns[0,:21])\n",
    "print(stim_label_allruns[0,-20:])\n",
    "\n",
    "# Plot the labels\n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label_allruns[0,:], c='orange')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data labels to account for hemodynamic lag\n",
    "shift_size = int(svd_hrf_lag / svd_TR)  # Convert the shift into TRs\n",
    "print('shift by %s TRs' % (shift_size))\n",
    "\n",
    "zero_shift = np.zeros((np.shape(stim_label_allruns)[0],shift_size)) #columns to insert at beginning\n",
    "end_trim = np.shape(stim_label_allruns)[1]-shift_size #trim columns at the end\n",
    "\n",
    "# insert shift columns at beginning and trim columns at end\n",
    "stim_label_allruns_shifted = np.hstack((zero_shift,stim_label_allruns[:,0:end_trim])) \n",
    "\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('stim_label_allruns_shifted has shape: ', np.shape(stim_label_allruns_shifted))\n",
    "print('')\n",
    "print('Trimmed AND shifted labels should have 3 leading zeros and 7 trailing zeros')\n",
    "print(stim_label_allruns_shifted[0,:15])\n",
    "print(stim_label_allruns_shifted[0,-15:])\n",
    "\n",
    "# Plot the original and shifted labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(stim_label_allruns[0,:], label='original', c='orange')\n",
    "ax.plot(stim_label_allruns_shifted[0,:], label='shifted', c='blue')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index row\n",
    "index_list = np.arange(len(stim_label_allruns_shifted[1]))\n",
    "stim_label_allruns_shifted[fam_row_labels['index'],:]=index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename labels\n",
    "familiarization_labels_shifted = stim_label_allruns_shifted\n",
    "print('familiarization label list - shape:', familiarization_labels_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Familiarization voxel x TR BOLD data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load voxel x TR data for each ROI\n",
    "masked_data = []\n",
    "masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    # load the mask for the corresponding ROI\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    # Load in data from matlab\n",
    "    in_file = (epi_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "    masked_data = scipy.io.loadmat(in_file)\n",
    "    masked_data = np.array(masked_data['data'])\n",
    "    assert masked_data.shape[1] == familiarization_labels_shifted.shape[1] #check that BOLD data and labels have same number \n",
    "    print(this_mask, masked_data.shape)\n",
    "    masked_data_all[mask_counter] = masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of the data and plot value of voxel_id across timeseries; make sure data are z-scored \n",
    "num_voxels = [0] * len(mask_list)\n",
    "voxel_id = 10\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    num_voxels[mask_counter] = masked_data_all[mask_counter].shape[0] #save number of voxels in each mask\n",
    "    \n",
    "    f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "    ax.plot(masked_data_all[mask_counter][voxel_id,:])\n",
    "    ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (this_mask, voxel_id))\n",
    "    ax.set_xlabel('TR')\n",
    "    ax.set_ylabel('Voxel Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape BOLD data and rename\n",
    "print('mask list:', mask_list)\n",
    "print('')\n",
    "bold_data=[]\n",
    "familiarization_bold_data = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print(this_mask)\n",
    "    # transpose bold data to make it timepoints x n_voxels\n",
    "    bold_data = np.transpose(masked_data_all[mask_counter])\n",
    "    print('Original BOLD data shape:', masked_data_all[mask_counter].shape)\n",
    "    print('Transposed BOLD data shape:', bold_data.shape)\n",
    "    print('')\n",
    "\n",
    "    familiarization_bold_data[mask_counter] = bold_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'reward'\n",
    "ses = 'ses-02'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_reward = n_runs[task_index]\n",
    "TRs_run_reward=TRs_run[task_index]-n_trunc_beginning-n_trunc_end\n",
    "print('TASK:', task)\n",
    "print('task index:', task_index)\n",
    "print('number of task runs:', n_runs_reward)\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('TRs per run before trimming = %s' % (TRs_run[task_index]))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('TRs per run after trimming = %s' % (TRs_run_reward))\n",
    "print('expected length of BOLD data series:', TRs_run_reward*n_runs_reward)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load reward regressor file\n",
    "'/jukebox/norman/emcdevitt/studies/SVD/data/behavioral/regressor/task-reward_regRow_all.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_row_labels={'cond': 0, 'repetition': 1, 'pairID_orig': 2, 'ipi': 3, 'order': 4, 'subcategory': 5,\n",
    "                'category': 6, 'imgID': 7, 'learningTrialOnset': 8, 'trialNum': 9, 'learningBlk': 10,\n",
    "                'index': 11, 'pairtype': 12, 'cycle': 13, 'rewardcond': 14, 'time': 15,\n",
    "                'response': 16, 'rt': 17, 'accuracy': 18, 'onset': 19, 'recorded': 20,\n",
    "                'fMRItrigger': 21, 'run': 22, 'uniquePairID': 23, 'exposureNum': 24, 'tr_original': 25, \n",
    "                'tr_trimmed': 26}\n",
    "print(reward_row_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stimulus labels from regressor file for each run and concatenate\n",
    "# NOTE: Regressor files are already trimmed (beginning only), but not shifted, in Matlab using gen_reward_regressor_0101.m\n",
    "\n",
    "stim_label = []\n",
    "stim_label_allruns = []\n",
    "stim_label_allruns_shifted = []\n",
    "\n",
    "# take individual run regressor files and concatenate them\n",
    "for run in range(1, n_runs_reward + 1):\n",
    "    in_file = (behavioral_dir + '%s_%s_task-%s_regressor-noshift-trim%dTRs_run-0%d.mat' % (sub, ses, task, n_trunc_beginning, run))\n",
    "    \n",
    "    # Load in data from matlab and trim end of labels\n",
    "    stim_label = scipy.io.loadmat(in_file);\n",
    "    stim_label = np.array(stim_label['regressor']);\n",
    "    stim_label = stim_label[:,:-n_trunc_end] # trim label end\n",
    "\n",
    "    # Store the data\n",
    "    if run == 1:\n",
    "        stim_label_allruns = stim_label;\n",
    "    else:       \n",
    "        stim_label_allruns = np.hstack((stim_label_allruns, stim_label))\n",
    "\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('')\n",
    "print('Trimmed (but not shifted) labels should begin with X-0-0-0-X and end with 11 trailing zeros')\n",
    "print(stim_label_allruns[0,:21])\n",
    "print(stim_label_allruns[0,-20:])\n",
    "\n",
    "# Plot the labels\n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label_allruns[0,:], c='orange')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label_allruns[reward_row_labels['run'],:], c='gray')\n",
    "ax.set_ylabel('Reward run #')\n",
    "ax.set_xlabel('TR')\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label_allruns[reward_row_labels['exposureNum'],:], c='orange')\n",
    "ax.set_ylabel('Exposure Num')\n",
    "ax.set_xlabel('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data labels to account for hemodynamic lag\n",
    "shift_size = int(svd_hrf_lag / svd_TR)  # Convert the shift into TRs\n",
    "print('shift by %s TRs' % (shift_size))\n",
    "\n",
    "zero_shift = np.zeros((np.shape(stim_label_allruns)[0],shift_size)) #columns to insert at beginning\n",
    "end_trim = np.shape(stim_label_allruns)[1]-shift_size #trim columns at the end\n",
    "\n",
    "# insert shift columns at beginning and trim columns at end\n",
    "stim_label_allruns_shifted = np.hstack((zero_shift,stim_label_allruns[:,0:end_trim])) \n",
    "\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('stim_label_allruns_shifted has shape: ', np.shape(stim_label_allruns_shifted))\n",
    "print('')\n",
    "print('Trimmed AND shifted labels should have 3 leading zeros and 8 trailing zeros')\n",
    "print(stim_label_allruns_shifted[0,:15])\n",
    "print(stim_label_allruns_shifted[0,-15:])\n",
    "\n",
    "# Plot the original and shifted labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(stim_label_allruns[0,:], label='original', c='orange')\n",
    "ax.plot(stim_label_allruns_shifted[0,:], label='shifted', c='blue')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index row\n",
    "index_list = np.arange(len(stim_label_allruns_shifted[1]))\n",
    "stim_label_allruns_shifted[reward_row_labels['index'],:]=index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename labels\n",
    "reward_labels_shifted = stim_label_allruns_shifted\n",
    "print('reward label list - shape:', reward_labels_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Reward voxel x TR BOLD data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load voxel x TR data for each ROI\n",
    "masked_data = []\n",
    "masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    # load the mask for the corresponding ROI\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    # Load in data from matlab\n",
    "    in_file = (epi_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "    masked_data = scipy.io.loadmat(in_file)\n",
    "    masked_data = np.array(masked_data['data'])\n",
    "    assert masked_data.shape[1] == reward_labels_shifted.shape[1] #check that BOLD data and labels have same number \n",
    "    print(this_mask, masked_data.shape)\n",
    "    masked_data_all[mask_counter] = masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of the data and plot value of voxel_id across timeseries; make sure data are z-scored \n",
    "num_voxels = [0] * len(mask_list)\n",
    "voxel_id = 10\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    num_voxels[mask_counter] = masked_data_all[mask_counter].shape[0] #save number of voxels in each mask\n",
    "    \n",
    "    f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "    ax.plot(masked_data_all[mask_counter][voxel_id,:])\n",
    "    ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (this_mask, voxel_id))\n",
    "    ax.set_xlabel('TR')\n",
    "    ax.set_ylabel('Voxel Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape BOLD data and rename\n",
    "bold_data=[]\n",
    "reward_bold_data = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print(this_mask)\n",
    "    # transpose bold data to make it timepoints x n_voxels\n",
    "    bold_data = np.transpose(masked_data_all[mask_counter])\n",
    "    print('Original BOLD data shape:', masked_data_all[mask_counter].shape)\n",
    "    print('Transposed BOLD data shape:', bold_data.shape)\n",
    "    print('')\n",
    "\n",
    "    reward_bold_data[mask_counter] = bold_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postfaces run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'postFaces'\n",
    "ses = 'ses-02'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_postfaces = n_runs[task_index]\n",
    "TRs_run_postfaces=TRs_run[task_index]-n_trunc_beginning-n_trunc_end\n",
    "print('TASK:', task)\n",
    "print('task index:', task_index)\n",
    "print('number of task runs:', n_runs_postfaces)\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('TRs per run before trimming = %s' % (TRs_run[task_index]))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('TRs per run after trimming = %s' % (TRs_run_postfaces))\n",
    "print('expected length of BOLD data series:', TRs_run_postfaces*n_runs_postfaces)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load postfaces regressor file\n",
    "/jukebox/norman/emcdevitt/studies/SVD/data/behavioral/regressor/task-postStudy_regRow_reshaped.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postfaces_row_labels={'cond': 0, 'repetition': 1, 'pairID_orig': 2, 'ipi': 3, 'order': 4, 'subcategory': 5,\n",
    "                'category': 6, 'imgID': 7, 'learningBlk': 8, 'learningTrial': 9, 'time': 10,\n",
    "                'response': 11, 'rt': 12, 'accuracy': 13, 'tr_original': 14, 'tr_trimmed': 15,\n",
    "                'uniquePairID': 16, 'exposureNum': 17, 'index': 18} #index row to be added\n",
    "print(postfaces_row_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Regressor files are already trimmed (beginning only), but not shifted, in Matlab using gen_postfaces_regressor_0101.m\n",
    "stim_label = []\n",
    "stim_label_shifted = []\n",
    "\n",
    "in_file = (behavioral_dir + '%s_%s_task-%s_regressor-noshift-trim%dTRs-reshaped_run-01.mat' % (sub, ses, task, n_trunc_beginning))\n",
    "stim_label = scipy.io.loadmat(in_file) # Load in data from matlab\n",
    "stim_label = np.array(stim_label['regressor'])\n",
    "stim_label = stim_label[:,:-n_trunc_end] # trim label end\n",
    "\n",
    "print(in_file)\n",
    "print('stim_label has shape: ', np.shape(stim_label))\n",
    "print('')\n",
    "print('Trimmed (but not shifted) labels should begin with alternating 1s and 0s and end with 9 trailing zeros')\n",
    "print(stim_label[0,:21])\n",
    "print(stim_label[0,-20:])\n",
    "\n",
    "# Plot the labels\n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label[0,:], c='orange') #faces only occured in condition 1(vio)\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data labels to account for hemodynamic lag\n",
    "shift_size = int(svd_hrf_lag / svd_TR)  # Convert the shift into TRs\n",
    "print('shift by %s TRs' % (shift_size))\n",
    "\n",
    "zero_shift = np.zeros((np.shape(stim_label)[0],shift_size)) #columns to insert at beginning\n",
    "end_trim = np.shape(stim_label)[1]-shift_size #trim columns at the end\n",
    "# insert shift columns at beginning and trim columns at end\n",
    "stim_label_shifted = np.hstack((zero_shift,stim_label[:,0:end_trim])) \n",
    "\n",
    "print('stim_label has shape: ', np.shape(stim_label))\n",
    "print('stim_label_shifted has shape: ', np.shape(stim_label_shifted))\n",
    "print('')\n",
    "print('Trimmed AND shifted labels should have 3 leading zeros and 6 trailing zeros')\n",
    "print(stim_label_shifted[0,:15])\n",
    "print(stim_label_shifted[0,-15:])\n",
    "\n",
    "# Plot the original and shifted labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(stim_label[0,:], label='original', c='orange')\n",
    "ax.plot(stim_label_shifted[0,:], label='shifted', c='blue')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index row\n",
    "index_list = np.arange(len(stim_label_shifted[1]))\n",
    "stim_label_shifted=np.vstack([stim_label_shifted, index_list])\n",
    "print(stim_label_shifted[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename labels\n",
    "postfaces_labels_shifted = stim_label_shifted\n",
    "print('label list - shape:', postfaces_labels_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Postfaces voxel x TR BOLD data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load voxel x TR data for each ROI\n",
    "masked_data = []\n",
    "masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    # load the mask for the corresponding ROI\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    # Load in data from matlab\n",
    "    in_file = (epi_dir + '%s_task-postfaces_run-01_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "    masked_data = scipy.io.loadmat(in_file)\n",
    "    masked_data = np.array(masked_data['data'])\n",
    "    assert masked_data.shape[1] == postfaces_labels_shifted.shape[1] #check that BOLD data and labels have same number \n",
    "    print(this_mask, masked_data.shape)\n",
    "    masked_data_all[mask_counter] = masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of the data and plot value of voxel_id across timeseries; make sure data are z-scored \n",
    "num_voxels = [0] * len(mask_list)\n",
    "voxel_id = 10\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    num_voxels[mask_counter] = masked_data_all[mask_counter].shape[0] #save number of voxels in each mask\n",
    "    \n",
    "    f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "    ax.plot(masked_data_all[mask_counter][voxel_id,:])\n",
    "    ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (this_mask, voxel_id))\n",
    "    ax.set_xlabel('TR')\n",
    "    ax.set_ylabel('Voxel Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape BOLD data and rename\n",
    "bold_data=[]\n",
    "postfaces_bold_data = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print(this_mask)\n",
    "    # transpose bold data to make it timepoints x n_voxels\n",
    "    bold_data = np.transpose(masked_data_all[mask_counter])\n",
    "    print('Original BOLD data shape:', masked_data_all[mask_counter].shape)\n",
    "    print('Transposed BOLD data shape:', bold_data.shape)\n",
    "    print('')\n",
    "\n",
    "    postfaces_bold_data[mask_counter] = bold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking BOLD data\n",
    "voxel_id=100\n",
    "mask_counter=0\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "ax.plot(postscenes_bold_data[mask_counter][:,voxel_id], label='postscenes', c='orange')\n",
    "ax.plot(postfaces_bold_data[mask_counter][:,voxel_id], label='postfaces', c='blue')\n",
    "ax.plot(familiarization_bold_data[mask_counter][:,voxel_id], label='familiarization', c='green')\n",
    "ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (mask_list[mask_counter], voxel_id))\n",
    "ax.set_xlabel('TR')\n",
    "ax.set_ylabel('Voxel Intensity')\n",
    "ax.legend()\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "ax.plot(study_bold_data[mask_counter][:,voxel_id], label='study', c='orange')\n",
    "ax.plot(reward_bold_data[mask_counter][:,voxel_id], label='reward', c='blue')\n",
    "ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (mask_list[mask_counter], voxel_id))\n",
    "ax.set_xlabel('TR')\n",
    "ax.set_ylabel('Voxel Intensity')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute pattern similarity\n",
    "- differentiation = corr(preA,postB)\n",
    "- B prediction = corr(preB,vioX) and corr(preB,vioY), then average the two correlations\n",
    "- B evidence in postfaces = corr(postB,postX) and corr(postB,postY), then average the two correlations\n",
    "- B evidence during reward learning = corr(postB,familiarizationA) and corr(postB,rewardAx4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for Fisher-transformed average\n",
    "def fisher_mean(correlations, axis=None):\n",
    "    return np.tanh(np.mean(np.arctanh(correlations), axis=axis)) #axis 0 for columns, 1 for rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dictionaries\n",
    "image_info={'condition': [], 'learningBlk': [], 'pairID': [],\n",
    "            'A_category': [], 'B_category': [], 'pairtype': [], \n",
    "            'A_imgID': [], 'B_imgID': [], 'X_imgID': [], 'Y_imgID': [],\n",
    "            'preA_indx': [], 'preB_indx': [], 'vioX_indx': [], 'vioY_indx': [], \n",
    "            'postB_indx': [], 'postX_indx': [], 'postY_indx': [],\n",
    "            'familiarization_indx': [], 'reward1_indx': [], 'reward2_indx': [],\n",
    "            'reward3_indx': [], 'reward4_indx': []}\n",
    "\n",
    "pairwise_data={'mask': [], 'condition': [], 'learningBlk': [], 'pairID': [], \n",
    "               'preApostB': [], 'preBvioX': [], 'preBvioY': [], 'preBavgXY': [],\n",
    "               'postBpostX': [], 'postBpostY': [], 'postBavgpostXY': [], 'rewardcond': [],\n",
    "               'postBfam': [], 'postBreward1': [], 'postBreward2': [], \n",
    "               'postBreward3': [], 'postBreward4': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pairs=96\n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "\n",
    "    # loop through each pair\n",
    "    for i in range(1,n_pairs+1):\n",
    "        # pull out trials corresponding to this pair\n",
    "        study_trials = study_labels_shifted[:,(study_labels_shifted[study_row_labels['uniquePairID'],:] == i)]\n",
    "        postscene_trial = postscenes_labels_shifted[:,(postscenes_labels_shifted[postscenes_row_labels['uniquePairID'],:] == i)]\n",
    "        if i < 49: #condition 1 only\n",
    "            postfaces_trials = postfaces_labels_shifted[:,(postfaces_labels_shifted[postfaces_row_labels['uniquePairID'],:] == i)]\n",
    "        else:\n",
    "            postfaces_trials = []\n",
    "        fam_trial = familiarization_labels_shifted[:,(familiarization_labels_shifted[fam_row_labels['uniquePairID'],:] == i)]\n",
    "        reward_trials = reward_labels_shifted[:,(reward_labels_shifted[reward_row_labels['uniquePairID'],:] == i)]\n",
    "        \n",
    "        this_cond = study_trials[study_row_labels['cond'],:]\n",
    "        this_blk = study_trials[study_row_labels['learningBlk'],:]\n",
    "        \n",
    "        # double checking that condition labels match\n",
    "        result = np.all(this_cond == this_cond[0])\n",
    "        if result:\n",
    "            this_cond = this_cond[0] #if all values are equal, then take the first value\n",
    "            assert this_cond == postscene_trial[postscenes_row_labels['cond']] #and make sure it matches postscene condition\n",
    "            if this_cond == 1:\n",
    "                assert this_cond == postfaces_trials[postfaces_row_labels['cond'],0] #and make sure it matches postfaces trials\n",
    "                assert this_cond == postfaces_trials[postfaces_row_labels['cond'],1] #and make sure it matches postfaces trials\n",
    "        else:\n",
    "            print('All study condition values are not same! Check pair #:', i)\n",
    "        \n",
    "        # double checking that learningBlks match\n",
    "        result = np.all(this_blk == this_blk[0])\n",
    "        if result:\n",
    "            this_blk = this_blk[0] #if all values are equal, then take the first value\n",
    "            assert this_blk == postscene_trial[postscenes_row_labels['learningBlk']]\n",
    "            if this_cond == 1:\n",
    "                assert this_blk == postfaces_trials[postfaces_row_labels['learningBlk'],0] #and make sure it matches postscene condition\n",
    "                assert this_blk == postfaces_trials[postfaces_row_labels['learningBlk'],1]\n",
    "        else:\n",
    "            print('All learningBlk values are not same! Check pair #:', i)\n",
    "            \n",
    "        # get indexes\n",
    "        preA_indx = study_trials[study_row_labels['index'],(study_trials[study_row_labels['cond_orig'],:] == 3) & (study_trials[study_row_labels['order'],:] == 1)]\n",
    "        preA_indx = int(preA_indx[0]) #cleanup\n",
    "        preB_indx = study_trials[study_row_labels['index'],(study_trials[study_row_labels['cond_orig'],:] == 3) & (study_trials[study_row_labels['order'],:] == 2)]\n",
    "        preB_indx = int(preB_indx[0]) #cleanup\n",
    "        postB_indx = postscene_trial[postscenes_row_labels['index']]\n",
    "        postB_indx = int(postB_indx[0]) #cleanup\n",
    "        \n",
    "        # get brain patterns\n",
    "        preA = study_bold_data[mask][preA_indx,:]\n",
    "        preB = study_bold_data[mask][preB_indx,:]\n",
    "        postB = postscenes_bold_data[mask][postB_indx,:]\n",
    "        \n",
    "        # compute differentiation correlation\n",
    "        preApostB = pearsonr(preA,postB)[0] #first value is Pearson's r, second value is p-value\n",
    "        \n",
    "        # compute B prediction -- violation condition only\n",
    "        if this_cond == 1:\n",
    "            vio_indx = study_trials[study_row_labels['index'],(study_trials[study_row_labels['category'],:] == 1)]\n",
    "            vioX_indx = int(vio_indx[0]) #cleanup\n",
    "            vioY_indx = int(vio_indx[1]) #cleanup\n",
    "            X_img = study_labels_shifted[study_row_labels['imgID'],vioX_indx]\n",
    "            Y_img = study_labels_shifted[study_row_labels['imgID'],vioY_indx]\n",
    "            \n",
    "            # brain patterns\n",
    "            vioX = study_bold_data[mask][vioX_indx,:]\n",
    "            vioY = study_bold_data[mask][vioY_indx,:]\n",
    "            \n",
    "            # correlations\n",
    "            preBvioX = pearsonr(preB,vioX)[0]\n",
    "            preBvioY = pearsonr(preB,vioY)[0]\n",
    "            preBavgXY = fisher_mean([preBvioX, preBvioY], axis=None)\n",
    "        else: \n",
    "            vio_indx = []\n",
    "            vioX_indx = np.nan\n",
    "            vioY_indx = np.nan\n",
    "            X_img = np.nan\n",
    "            Y_img = np.nan\n",
    "            vioX = []\n",
    "            vioY = []\n",
    "            preBvioX = np.nan\n",
    "            preBvioY = np.nan\n",
    "            preBavgXY = np.nan\n",
    "\n",
    "        # compute B evidence during postfaces -- violation condition only\n",
    "        if this_cond == 1:\n",
    "            postX_indx = postfaces_trials[postfaces_row_labels['index'],(postfaces_trials[postfaces_row_labels['repetition'],:] == 4)] #X=4, Y=6\n",
    "            postY_indx = postfaces_trials[postfaces_row_labels['index'],(postfaces_trials[postfaces_row_labels['repetition'],:] == 6)]\n",
    "            postX_indx = int(postX_indx[0]) #cleanup\n",
    "            postY_indx = int(postY_indx[0]) #cleanup\n",
    "            postX_img = postfaces_labels_shifted[postfaces_row_labels['imgID'],postX_indx]\n",
    "            postY_img = postfaces_labels_shifted[postfaces_row_labels['imgID'],postY_indx]\n",
    "            assert postX_img == X_img #check that imgIDs match for vioX and postX\n",
    "            assert postY_img == Y_img #check that imgIDs match for vioY and postY\n",
    "            \n",
    "            # brain patterns\n",
    "            postX = postfaces_bold_data[mask][postX_indx,:]\n",
    "            postY = postfaces_bold_data[mask][postY_indx,:]\n",
    "            \n",
    "            # correlations\n",
    "            postBpostX = pearsonr(postB,postX)[0]\n",
    "            postBpostY = pearsonr(postB,postY)[0]\n",
    "            postBavgpostXY = fisher_mean([postBpostX, postBpostY], axis=None)\n",
    "\n",
    "        else: \n",
    "            postX_indx = np.nan\n",
    "            postY_indx = np.nan\n",
    "            postX_img = np.nan\n",
    "            postY_img = np.nan\n",
    "            postX = []\n",
    "            postY = []\n",
    "            postBpostX = np.nan\n",
    "            postBpostY = np.nan\n",
    "            postBavgpostXY = np.nan\n",
    "        \n",
    "        # double checking reward trials: condition\n",
    "        result = np.all(reward_trials[reward_row_labels['cond']] == reward_trials[reward_row_labels['cond'],0])\n",
    "        if result:\n",
    "            assert this_cond == reward_trials[reward_row_labels['cond'],0] #then make sure it matches study condition\n",
    "        else:\n",
    "            print('All condition values are not same! Check pair #:', i)\n",
    "        \n",
    "        # check that all rewardconds are the same\n",
    "        result = np.all(reward_trials[reward_row_labels['rewardcond']] == reward_trials[reward_row_labels['rewardcond'],0])\n",
    "        if result:\n",
    "            rewardcond = reward_trials[reward_row_labels['rewardcond'],0]\n",
    "            assert rewardcond == fam_trial[fam_row_labels['rewardcond']]\n",
    "        else:\n",
    "            print('All reward condition values are not same! Check pair #:', i)\n",
    "        \n",
    "        # check A scene image during reward trials\n",
    "        result = np.all(reward_trials[reward_row_labels['imgID']] == reward_trials[reward_row_labels['imgID'],0]) #check all reward images are the same\n",
    "        if result:\n",
    "            assert reward_trials[reward_row_labels['imgID'],0] == study_labels_shifted[study_row_labels['imgID'],preA_indx] #check that reward matches study phase image\n",
    "        else:\n",
    "            print('All reward condition values are not same! Check pair #:', i)\n",
    "        \n",
    "        #reward trials\n",
    "        familiarization_indx = int(fam_trial[fam_row_labels['index'],0])\n",
    "        reward1_indx = int(reward_trials[reward_row_labels['index'],0])\n",
    "        reward2_indx = int(reward_trials[reward_row_labels['index'],1])\n",
    "        reward3_indx = int(reward_trials[reward_row_labels['index'],2])\n",
    "        reward4_indx = int(reward_trials[reward_row_labels['index'],3])\n",
    "        \n",
    "        # brain patterns\n",
    "        familiarization = familiarization_bold_data[mask][familiarization_indx,:]\n",
    "        reward1 = reward_bold_data[mask][reward1_indx,:]\n",
    "        reward2 = reward_bold_data[mask][reward2_indx,:]\n",
    "        reward3 = reward_bold_data[mask][reward3_indx,:]\n",
    "        reward4 = reward_bold_data[mask][reward4_indx,:]\n",
    "            \n",
    "        # correlations\n",
    "        postBfam = pearsonr(postB,familiarization)[0]\n",
    "        postBreward1 = pearsonr(postB,reward1)[0]\n",
    "        postBreward2 = pearsonr(postB,reward2)[0]\n",
    "        postBreward3 = pearsonr(postB,reward3)[0]\n",
    "        postBreward4 = pearsonr(postB,reward4)[0]\n",
    "        \n",
    "        # other information\n",
    "        # category info -- indoor(1) or outdoor(2)\n",
    "        A_cat = study_labels_shifted[study_row_labels['subcategory'],preA_indx]\n",
    "        B_cat = study_labels_shifted[study_row_labels['subcategory'],preB_indx]\n",
    "        pairtype = reward_labels_shifted[reward_row_labels['pairtype'],reward1_indx]\n",
    "        \n",
    "        # fill in image_info for this subject (only need to do this for one loop)\n",
    "        if mask == 0:\n",
    "            image_info['condition'].append(this_cond)\n",
    "            image_info['learningBlk'].append(this_blk)\n",
    "            image_info['pairID'].append(i)\n",
    "            image_info['A_category'].append(study_labels_shifted[study_row_labels['subcategory'],preA_indx])\n",
    "            image_info['B_category'].append(study_labels_shifted[study_row_labels['subcategory'],preB_indx])\n",
    "            image_info['pairtype'].append(pairtype)\n",
    "            image_info['A_imgID'].append(study_labels_shifted[study_row_labels['imgID'],preA_indx])\n",
    "            image_info['B_imgID'].append(study_labels_shifted[study_row_labels['imgID'],preB_indx])\n",
    "            image_info['X_imgID'].append(X_img)\n",
    "            image_info['Y_imgID'].append(Y_img)\n",
    "            image_info['preA_indx'].append(preA_indx)\n",
    "            image_info['preB_indx'].append(preB_indx)\n",
    "            image_info['vioX_indx'].append(vioX_indx)\n",
    "            image_info['vioY_indx'].append(vioY_indx)\n",
    "            image_info['postB_indx'].append(postB_indx)\n",
    "            image_info['postX_indx'].append(postX_indx)\n",
    "            image_info['postY_indx'].append(postY_indx)\n",
    "            image_info['familiarization_indx'].append(familiarization_indx)\n",
    "            image_info['reward1_indx'].append(reward1_indx)\n",
    "            image_info['reward2_indx'].append(reward2_indx)\n",
    "            image_info['reward3_indx'].append(reward3_indx)\n",
    "            image_info['reward4_indx'].append(reward4_indx)\n",
    "        \n",
    "        to_do = 'TODO'\n",
    "        \n",
    "        # fill in pairwise_data for this subject and mask\n",
    "        pairwise_data['mask'].append(this_mask)\n",
    "        pairwise_data['condition'].append(this_cond)\n",
    "        pairwise_data['learningBlk'].append(this_blk)\n",
    "        pairwise_data['pairID'].append(i)\n",
    "        pairwise_data['preApostB'].append(preApostB)\n",
    "        pairwise_data['preBvioX'].append(preBvioX)\n",
    "        pairwise_data['preBvioY'].append(preBvioY)\n",
    "        pairwise_data['preBavgXY'].append(preBavgXY)\n",
    "        pairwise_data['postBpostX'].append(postBpostX)\n",
    "        pairwise_data['postBpostY'].append(postBpostY)\n",
    "        pairwise_data['postBavgpostXY'].append(postBavgpostXY)\n",
    "        pairwise_data['rewardcond'].append(rewardcond)\n",
    "        pairwise_data['postBfam'].append(postBfam)\n",
    "        pairwise_data['postBreward1'].append(postBreward1)\n",
    "        pairwise_data['postBreward2'].append(postBreward2)\n",
    "        pairwise_data['postBreward3'].append(postBreward3)\n",
    "        pairwise_data['postBreward4'].append(postBreward4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "df = pd.DataFrame.from_dict(image_info)\n",
    "\n",
    "# recode condition, pairtype\n",
    "print(conditions)\n",
    "df = df.replace({\"condition\": conditions})\n",
    "df = df.replace({\"pairtype\": pair_type})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with pairwise pearson r values\n",
    "pearson_r = pd.DataFrame.from_dict(pairwise_data)\n",
    "assert pearson_r.shape[0] == len(mask_list)*n_pairs #check\n",
    "\n",
    "# recode condition and rewardcond\n",
    "pearson_r = pearson_r.replace({\"condition\": conditions})\n",
    "pearson_r = pearson_r.replace({\"rewardcond\": reward_cond})\n",
    "pearson_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with pairwise fisher z values\n",
    "fisher_z = pd.DataFrame.from_dict(pairwise_data)\n",
    "fisher_z['preApostB'] = fisher_z['preApostB'].apply(np.arctanh) # fisher transform\n",
    "fisher_z['preBvioX'] = fisher_z['preBvioX'].apply(np.arctanh)\n",
    "fisher_z['preBvioY'] = fisher_z['preBvioY'].apply(np.arctanh)\n",
    "fisher_z['preBavgXY'] = fisher_z['preBavgXY'].apply(np.arctanh)\n",
    "fisher_z['postBpostX'] = fisher_z['postBpostX'].apply(np.arctanh)\n",
    "fisher_z['postBpostY'] = fisher_z['postBpostY'].apply(np.arctanh)\n",
    "fisher_z['postBavgpostXY'] = fisher_z['postBavgpostXY'].apply(np.arctanh)\n",
    "fisher_z['postBfam'] = fisher_z['postBfam'].apply(np.arctanh)\n",
    "fisher_z['postBreward1'] = fisher_z['postBreward1'].apply(np.arctanh)\n",
    "fisher_z['postBreward2'] = fisher_z['postBreward2'].apply(np.arctanh)\n",
    "fisher_z['postBreward3'] = fisher_z['postBreward3'].apply(np.arctanh)\n",
    "fisher_z['postBreward4'] = fisher_z['postBreward4'].apply(np.arctanh)\n",
    "\n",
    "# recode condition and rewardcond\n",
    "fisher_z = fisher_z.replace({\"condition\": conditions})\n",
    "fisher_z = fisher_z.replace({\"rewardcond\": reward_cond})\n",
    "\n",
    "fisher_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute avg differentiation for each condition using fisher z values\n",
    "differentiation = fisher_z.groupby(['mask', 'condition'], as_index=False)['preApostB'].mean()\n",
    "assert differentiation.shape[0] == len(mask_list)*2 #2 conditions\n",
    "differentiation.rename(columns={'preApostB': 'preApostB_z'}, inplace=True)\n",
    "\n",
    "differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vio-nonvio using Fisher z values\n",
    "n_conditions = 2\n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    vio = differentiation[(differentiation['mask']==this_mask) & (differentiation['condition'] == 'vio')]\n",
    "    nonvio = differentiation[(differentiation['mask']==this_mask) & (differentiation['condition'] == 'nonvio')]\n",
    "    vio_nonvio=[]\n",
    "    vio_nonvio = vio['preApostB_z'].values[0] - nonvio['preApostB_z'].values[0]\n",
    "    differentiation = differentiation.append({'mask': this_mask, 'condition': 'vio-nonvio', 'preApostB_z': vio_nonvio}, ignore_index=True)\n",
    "\n",
    "# add column for Pearson r values and transform from z to r\n",
    "differentiation['preApostB_r'] = differentiation['preApostB_z'].apply(np.tanh)\n",
    "\n",
    "differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute avg Bprediction during familiarization and reward learning trials for each condition\n",
    "Bprediction_reward = fisher_z.groupby(['mask', 'condition'], as_index=False)['postBfam', 'postBreward1', 'postBreward2', 'postBreward3', 'postBreward4'].mean()\n",
    "\n",
    "assert Bprediction_reward.shape[0] == len(mask_list)*2 #2 conditions\n",
    "Bprediction_reward.rename(columns={'postBfam': 'postBfam_z', 'postBreward1': 'postBreward1_z', \n",
    "                                   'postBreward2': 'postBreward2_z', 'postBreward3': 'postBreward3_z', \n",
    "                                   'postBreward4': 'postBreward4_z'}, inplace=True)\n",
    "\n",
    "Bprediction_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vio-nonvio using Fisher z values\n",
    "n_conditions = 2\n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    vio = Bprediction_reward[(Bprediction_reward['mask']==this_mask) & (Bprediction_reward['condition'] == 'vio')]\n",
    "    nonvio = Bprediction_reward[(Bprediction_reward['mask']==this_mask) & (Bprediction_reward['condition'] == 'nonvio')]\n",
    "    \n",
    "    vio_nonvio_fam=[]\n",
    "    vio_nonvio_1=[]\n",
    "    vio_nonvio_2=[]\n",
    "    vio_nonvio_3=[]\n",
    "    vio_nonvio_4=[]\n",
    "    \n",
    "    vio_nonvio_fam = vio['postBfam_z'].values[0] - nonvio['postBfam_z'].values[0]\n",
    "    vio_nonvio_1 = vio['postBreward1_z'].values[0] - nonvio['postBreward1_z'].values[0]\n",
    "    vio_nonvio_2 = vio['postBreward2_z'].values[0] - nonvio['postBreward2_z'].values[0]\n",
    "    vio_nonvio_3 = vio['postBreward3_z'].values[0] - nonvio['postBreward3_z'].values[0]\n",
    "    vio_nonvio_4 = vio['postBreward4_z'].values[0] - nonvio['postBreward4_z'].values[0]\n",
    "    Bprediction_reward = Bprediction_reward.append({'mask': this_mask, 'condition': 'vio-nonvio', 'postBfam_z': vio_nonvio_fam, \n",
    "                                                    'postBreward1_z': vio_nonvio_1, 'postBreward2_z': vio_nonvio_2,\n",
    "                                                    'postBreward3_z': vio_nonvio_3, 'postBreward4_z': vio_nonvio_4}, ignore_index=True)\n",
    "\n",
    "# add column for Pearson r values and transform from z to r\n",
    "Bprediction_reward['postBfam_r'] = Bprediction_reward['postBfam_z'].apply(np.tanh)\n",
    "Bprediction_reward['postBreward1_r'] = Bprediction_reward['postBreward1_z'].apply(np.tanh)\n",
    "Bprediction_reward['postBreward2_r'] = Bprediction_reward['postBreward2_z'].apply(np.tanh)\n",
    "Bprediction_reward['postBreward3_r'] = Bprediction_reward['postBreward3_z'].apply(np.tanh)\n",
    "Bprediction_reward['postBreward4_r'] = Bprediction_reward['postBreward4_z'].apply(np.tanh)\n",
    "\n",
    "\n",
    "Bprediction_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute 2nd order correlations\n",
    "- Correlate B prediction (preB,vioXY) with differentiation (preA,postB) for violation pairs\n",
    "- Correlate B evidence during postfaces (postB,avgpostXY) with differentiation (preA,postB) in violation condition\n",
    "- Correlate B prediction during reward learning with differentiation (preA,postB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate B prediction during violation events with differentiation using pairwise pearson r values\n",
    "Bpredict_diff_corr={'mask': [], 'condition': [], 'BpredictDiff_z': [], 'BpredictDiff_r': []}\n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    vio_only = pearson_r[(pearson_r['mask']==this_mask) & (pearson_r['condition'] == 'vio')]\n",
    "    correlation = vio_only['preApostB'].corr(vio_only['preBavgXY'])\n",
    "    \n",
    "    Bpredict_diff_corr['mask'].append(this_mask)\n",
    "    Bpredict_diff_corr['condition'].append('vio') #only computed for violation condition\n",
    "    Bpredict_diff_corr['BpredictDiff_r'].append(correlation)\n",
    "    Bpredict_diff_corr['BpredictDiff_z'].append(np.arctanh(correlation))\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(Bpredict_diff_corr)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate B evidence during postfaces with differentiation using pairwise pearson r values\n",
    "Bevidence_postfaces_corr={'mask': [], 'condition': [], 'BevidenceFaces_z': [], 'BevidenceFaces_r': []}\n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    vio_only = pearson_r[(pearson_r['mask']==this_mask) & (pearson_r['condition'] == 'vio')]\n",
    "    correlation = vio_only['preApostB'].corr(vio_only['postBavgpostXY'])\n",
    "    \n",
    "    Bevidence_postfaces_corr['mask'].append(this_mask)\n",
    "    Bevidence_postfaces_corr['condition'].append('vio') #only computed for violation condition\n",
    "    Bevidence_postfaces_corr['BevidenceFaces_r'].append(correlation)\n",
    "    Bevidence_postfaces_corr['BevidenceFaces_z'].append(np.arctanh(correlation))\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(Bevidence_postfaces_corr)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate B prediction during reward learning with differentiation using pairwise pearson r values\n",
    "Bpredict_reward_diff_corr={'mask': [], 'condition': [], 'BpredictFamiliarization_diff_z': [], \n",
    "                      'BpredictReward1_diff_z': [], 'BpredictReward2_diff_z': [], \n",
    "                      'BpredictReward3_diff_z': [], 'BpredictReward4_diff_z': [],\n",
    "                      'BpredictFamiliarization_diff_r': [], 'BpredictReward1_diff_r': [],\n",
    "                      'BpredictReward2_diff_r': [], 'BpredictReward3_diff_r': [],\n",
    "                      'BpredictReward4_diff_r': []}\n",
    "\n",
    "corr_conditions = ['vio','nonvio','all']\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    # loop through each condition (vio, nonvio, and both conditions together i.e. all)\n",
    "    for cond in range(len(corr_conditions)):\n",
    "        this_cond = corr_conditions[cond]\n",
    "\n",
    "        if this_cond == 'all':\n",
    "            selected_data = pearson_r[(pearson_r['mask']==this_mask)]\n",
    "        else:\n",
    "            selected_data = pearson_r[(pearson_r['mask']==this_mask) & (pearson_r['condition'] == this_cond)]\n",
    "        \n",
    "        correlation = selected_data['preApostB'].corr(selected_data['postBfam'])\n",
    "        correlation1 = selected_data['preApostB'].corr(selected_data['postBreward1'])\n",
    "        correlation2 = selected_data['preApostB'].corr(selected_data['postBreward2'])\n",
    "        correlation3 = selected_data['preApostB'].corr(selected_data['postBreward3'])\n",
    "        correlation4 = selected_data['preApostB'].corr(selected_data['postBreward4'])\n",
    "    \n",
    "        Bpredict_reward_diff_corr['mask'].append(this_mask)\n",
    "        Bpredict_reward_diff_corr['condition'].append(this_cond) #only computed for violation condition\n",
    "        Bpredict_reward_diff_corr['BpredictFamiliarization_diff_r'].append(correlation)\n",
    "        Bpredict_reward_diff_corr['BpredictFamiliarization_diff_z'].append(np.arctanh(correlation))\n",
    "        Bpredict_reward_diff_corr['BpredictReward1_diff_r'].append(correlation1)\n",
    "        Bpredict_reward_diff_corr['BpredictReward1_diff_z'].append(np.arctanh(correlation1))\n",
    "        Bpredict_reward_diff_corr['BpredictReward2_diff_r'].append(correlation2)\n",
    "        Bpredict_reward_diff_corr['BpredictReward2_diff_z'].append(np.arctanh(correlation2))\n",
    "        Bpredict_reward_diff_corr['BpredictReward3_diff_r'].append(correlation3)\n",
    "        Bpredict_reward_diff_corr['BpredictReward3_diff_z'].append(np.arctanh(correlation3))\n",
    "        Bpredict_reward_diff_corr['BpredictReward4_diff_r'].append(correlation4)\n",
    "        Bpredict_reward_diff_corr['BpredictReward4_diff_z'].append(np.arctanh(correlation4))\n",
    "\n",
    "df4 = pd.DataFrame.from_dict(Bpredict_reward_diff_corr)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomization tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# testing\n",
    "arr = np.arange(10)\n",
    "print('original:', arr)\n",
    "for i in range(1,10): #shuffle 10 times\n",
    "    arr1 = rng.permutation(arr)\n",
    "    print('permutation #', i, ':', arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Differentiation: preApostB\n",
    "- shuffle within condition (vio, nonvio)\n",
    "- hold preA constant and shuffle postBs\n",
    "- compute corr(preApostBshuffled)\n",
    "- Fisher transform, average within condition, compute vio-nonvio difference\n",
    "- save 1000 permutation values to dictionary\n",
    "- compute z-score of true difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "\n",
    "# Setup dictionaries\n",
    "image_info_permutation={'mask': [], 'iteration': [], 'condition': [], 'pairID': [], \n",
    "                        'A_category': [], 'Bshuffled_category': [], \n",
    "                        'A_imgID': [], 'Bshuffled_imgID': [],\n",
    "                        'preA_indx': [], 'postB_indx': [], 'postBshuffled_indx': [], \n",
    "                        'preApostBshuffled_r': [], 'preApostBshuffled_z': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is image_info\n",
    "\n",
    "# pull out columns of interest for each condition\n",
    "vio_pairs = df.loc[(df['condition']=='vio'),['condition', 'learningBlk', 'pairID', 'A_category', 'B_category', \n",
    "                                             'A_imgID', 'B_imgID', 'preA_indx', 'postB_indx']]\n",
    "nonvio_pairs = df.loc[(df['condition']=='nonvio'),['condition', 'learningBlk', 'pairID', 'A_category', 'B_category', \n",
    "                                             'A_imgID', 'B_imgID', 'preA_indx', 'postB_indx']]\n",
    "display(vio_pairs)\n",
    "display(nonvio_pairs)\n",
    "\n",
    "# convert dataframes to dictionaries\n",
    "vio_pairs = vio_pairs.to_dict('list')\n",
    "nonvio_pairs = nonvio_pairs.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pairs=96 \n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    \n",
    "    # loop through each iteration\n",
    "    for iter in range(1,n_iter+1):\n",
    "        if (iter/500).is_integer():\n",
    "            print(this_mask, 'iteration #:', iter)\n",
    "            \n",
    "        vio_pairs['postBshuffled_indx'] = np.nan #clear\n",
    "        nonvio_pairs['postBshuffled_indx'] = np.nan #clear\n",
    "\n",
    "        # shuffle postBs within condition\n",
    "        vio_pairs['postBshuffled_indx'] = rng.permutation(vio_pairs['postB_indx'])\n",
    "        nonvio_pairs['postBshuffled_indx'] = rng.permutation(nonvio_pairs['postB_indx'])\n",
    "\n",
    "        # loop through each pair\n",
    "        for i in range(1,n_pairs+1):\n",
    "            \n",
    "            if i < 49: #violation\n",
    "                assert vio_pairs['pairID'][i-1] == i\n",
    "                this_cond = vio_pairs['condition'][i-1]\n",
    "                preA_indx = vio_pairs['preA_indx'][i-1]\n",
    "                postB_indx = vio_pairs['postB_indx'][i-1]\n",
    "                postBshuffled_indx = vio_pairs['postBshuffled_indx'][i-1]\n",
    "                A_cat = vio_pairs['A_category'][i-1]\n",
    "                A_img = vio_pairs['A_imgID'][i-1]\n",
    "            else: #nonviolation\n",
    "                assert nonvio_pairs['pairID'][i-49] == i\n",
    "                this_cond = nonvio_pairs['condition'][i-49]\n",
    "                preA_indx = nonvio_pairs['preA_indx'][i-49]\n",
    "                postB_indx = nonvio_pairs['postB_indx'][i-49]\n",
    "                postBshuffled_indx = nonvio_pairs['postBshuffled_indx'][i-49]\n",
    "                A_cat = nonvio_pairs['A_category'][i-49]\n",
    "                A_img = nonvio_pairs['A_imgID'][i-49]\n",
    "            \n",
    "            # get brain patterns\n",
    "            preA = study_bold_data[mask][preA_indx,:]\n",
    "            postBshuffled = postscenes_bold_data[mask][postBshuffled_indx,:]\n",
    "\n",
    "            # compute differentiation correlation\n",
    "            preApostBshuffled = pearsonr(preA,postBshuffled)[0] #first value is Pearson's r, second value is p-value\n",
    "            \n",
    "            #get info about postBshuffled image\n",
    "            postBshuffled_cat = postscenes_labels_shifted[postscenes_row_labels['subcategory'],postBshuffled_indx]\n",
    "            postBshuffled_img = postscenes_labels_shifted[postscenes_row_labels['imgID'],postBshuffled_indx]\n",
    "\n",
    "            image_info_permutation['mask'].append(this_mask)\n",
    "            image_info_permutation['iteration'].append(iter)\n",
    "            image_info_permutation['condition'].append(this_cond)\n",
    "            image_info_permutation['pairID'].append(i)\n",
    "            image_info_permutation['A_category'].append(A_cat)\n",
    "            image_info_permutation['Bshuffled_category'].append(postBshuffled_cat)\n",
    "            image_info_permutation['A_imgID'].append(A_img)\n",
    "            image_info_permutation['Bshuffled_imgID'].append(postBshuffled_img)\n",
    "            image_info_permutation['preA_indx'].append(preA_indx)\n",
    "            image_info_permutation['postB_indx'].append(postB_indx)\n",
    "            image_info_permutation['postBshuffled_indx'].append(postBshuffled_indx)\n",
    "            image_info_permutation['preApostBshuffled_r'].append(preApostBshuffled)\n",
    "            image_info_permutation['preApostBshuffled_z'].append(np.arctanh(preApostBshuffled)) #Fisher transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute avg differentiation for each condition using fisher z values\n",
    "differentiation_shuffled = pd.DataFrame.from_dict(image_info_permutation)\n",
    "differentiation_shuffled = differentiation_shuffled.groupby(['mask', 'iteration', 'condition'], as_index=False)['preApostBshuffled_z'].mean()\n",
    "\n",
    "assert differentiation_shuffled.shape[0] == len(mask_list)*n_iter*2 #2 conditions\n",
    "differentiation_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vio-nonvio using Fisher z values\n",
    "n_conditions = 2\n",
    "\n",
    "# setup dictionary\n",
    "differentiation_perm={'mask': [], 'iteration': [], 'preApostBshuffled_vio_z': [], \n",
    "                      'preApostBshuffled_nonvio_z': [], 'preApostBshuffled_vio-nonvio_z': [], \n",
    "                      'preApostBshuffled_vio-nonvio_r': []}\n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    for iter in range(1,n_iter+1):\n",
    "        vio = differentiation_shuffled[(differentiation_shuffled['mask']==this_mask) & (differentiation_shuffled['iteration'] == iter) & (differentiation_shuffled['condition'] == 'vio')]\n",
    "        nonvio = differentiation_shuffled[(differentiation_shuffled['mask']==this_mask) & (differentiation_shuffled['iteration'] == iter) & (differentiation_shuffled['condition'] == 'nonvio')]\n",
    "        vio_nonvio=[]\n",
    "        vio_nonvio = vio['preApostBshuffled_z'].values[0] - nonvio['preApostBshuffled_z'].values[0]\n",
    "        differentiation_perm['mask'].append(this_mask)\n",
    "        differentiation_perm['iteration'].append(iter)\n",
    "        differentiation_perm['preApostBshuffled_vio_z'].append(vio['preApostBshuffled_z'].values[0])\n",
    "        differentiation_perm['preApostBshuffled_nonvio_z'].append(nonvio['preApostBshuffled_z'].values[0])\n",
    "        differentiation_perm['preApostBshuffled_vio-nonvio_z'].append(vio_nonvio)\n",
    "        differentiation_perm['preApostBshuffled_vio-nonvio_r'].append(np.tanh(vio_nonvio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for each mask and compute z-score\n",
    "\n",
    "# setup dictionary\n",
    "differentiation_zscore={'mask': [], 'vio-nonvio_observed_fisherz': [], 'shuffled_mean': [],\n",
    "                        'shuffled_std': [], 'vio-nonvio_permutation_zscore': []}\n",
    "\n",
    "# convert to dataframe\n",
    "shuffled_data = pd.DataFrame.from_dict(differentiation_perm)\n",
    "\n",
    "n_subplots = len(mask_list)\n",
    "f, ax = plt.subplots(1, n_subplots, sharey=True, figsize=(n_subplots*5,5)) #figsize=(10,5)\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    plot_title = 'mask=%s' %(this_mask)\n",
    "    \n",
    "    # get shuffled data for this mask\n",
    "    select_shuffled_data = shuffled_data[(shuffled_data['mask']==this_mask)]\n",
    "    assert select_shuffled_data.shape[0] == n_iter\n",
    "    shuffled_mean = select_shuffled_data['preApostBshuffled_vio-nonvio_z'].mean()\n",
    "    shuffled_std = select_shuffled_data['preApostBshuffled_vio-nonvio_z'].std(ddof=0) #population std\n",
    "    \n",
    "    # get observed values for this mask\n",
    "    select_true_data = differentiation[(differentiation['mask']==this_mask) & (differentiation['condition']=='vio-nonvio')]\n",
    "    observed_value = select_true_data['preApostB_z'].values[0]\n",
    "    \n",
    "    # compute z-score\n",
    "    z_score = (observed_value - shuffled_mean)/shuffled_std\n",
    "    print('z score:', z_score, 'n_iter:', n_iter)\n",
    "    \n",
    "    differentiation_zscore['mask'].append(this_mask)\n",
    "    differentiation_zscore['vio-nonvio_observed_fisherz'].append(observed_value)\n",
    "    differentiation_zscore['shuffled_mean'].append(shuffled_mean)\n",
    "    differentiation_zscore['shuffled_std'].append(shuffled_std)\n",
    "    differentiation_zscore['vio-nonvio_permutation_zscore'].append(z_score)\n",
    "    \n",
    "    sns.histplot(data=select_shuffled_data, x=\"preApostBshuffled_vio-nonvio_z\", kde=True, ax=ax[mask])\n",
    "    ax[mask].axvline(x=observed_value, color='red')\n",
    "    ax[mask].set_title(plot_title)\n",
    "    \n",
    "df999 = pd.DataFrame.from_dict(differentiation_zscore)\n",
    "display(df999)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B prediction: preBavgXY\n",
    "- violation condition only\n",
    "- hold XY and preApostB differentiation value constant; shuffle preBs\n",
    "- compute corr(preBshuffled,vioX) and corr(preBshuffled,vioY); Fisher transform and average to get preBshuffled,avgXY\n",
    "- correlated preBshuffled,avgXY with preApostB\n",
    "- save 1000 permuted correlation values to dictionary\n",
    "- compute z-score of true correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is image_info\n",
    "\n",
    "# pull out columns of interest for each condition\n",
    "vio_pairs = df.loc[(df['condition']=='vio'),['condition', 'learningBlk', 'pairID', 'A_category', 'B_category', \n",
    "                                             'preA_indx', 'preB_indx', 'vioX_indx', 'vioY_indx', 'postB_indx']]\n",
    "\n",
    "display(vio_pairs)\n",
    "\n",
    "# convert dataframes to dictionaries\n",
    "vio_pairs = vio_pairs.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pairs=48 #violation condition only \n",
    "\n",
    "# Setup dictionaries\n",
    "image_info_Bpredict_permutation={'mask': [], 'iteration': [], 'condition': [], 'pairID': [], \n",
    "                        'preA_indx': [], 'preB_indx': [], 'preBshuffled_indx': [], 'postB_indx': [],\n",
    "                        'vioX_indx': [], 'vioY_indx': [],\n",
    "                        'preBshuffledvioX_r': [], 'preBshuffledvioY_r': [], 'preBshuffledavgXY_r': [], \n",
    "                        'preApostB_r': []}\n",
    "\n",
    "Bpredict_diff_corr_shuffled={'mask': [], 'iteration': [], 'BpredictDiff_z': [], 'BpredictDiff_r': []}\n",
    "\n",
    "# loop through each mask\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "\n",
    "    # loop through each iteration\n",
    "    for iter in range(1,n_iter+1):\n",
    "        if (iter/500).is_integer():\n",
    "            print(this_mask, 'iteration #:', iter)\n",
    "            \n",
    "        # shuffle preBs within condition\n",
    "        vio_pairs['preBshuffled_indx'] = np.nan #clear\n",
    "        vio_pairs['preBshuffled_indx'] = rng.permutation(vio_pairs['preB_indx'])\n",
    "\n",
    "        # loop through each pair and compute B prediction\n",
    "        for i in range(1,n_pairs+1):\n",
    "            assert vio_pairs['pairID'][i-1] == i\n",
    "            this_cond = vio_pairs['condition'][i-1]\n",
    "            preA_indx = vio_pairs['preA_indx'][i-1]\n",
    "            preB_indx = vio_pairs['preB_indx'][i-1]\n",
    "            postB_indx = vio_pairs['postB_indx'][i-1]\n",
    "            vioX_indx = int(vio_pairs['vioX_indx'][i-1])\n",
    "            vioY_indx = int(vio_pairs['vioY_indx'][i-1])\n",
    "            preBshuffled_indx = vio_pairs['preBshuffled_indx'][i-1]\n",
    " \n",
    "            # brain patterns\n",
    "            preA = study_bold_data[mask][preA_indx,:]\n",
    "            preBshuffled = study_bold_data[mask][preBshuffled_indx,:]\n",
    "            vioX = study_bold_data[mask][vioX_indx,:]\n",
    "            vioY = study_bold_data[mask][vioY_indx,:]\n",
    "            postB = postscenes_bold_data[mask][postB_indx,:]\n",
    "            \n",
    "            # correlations\n",
    "            preBshuffledvioX = pearsonr(preBshuffled,vioX)[0]\n",
    "            preBshuffledvioY = pearsonr(preBshuffled,vioY)[0]\n",
    "            preBshuffledavgXY = fisher_mean([preBshuffledvioX, preBshuffledvioY], axis=None)\n",
    "            preApostB = pearsonr(preA,postB)[0]\n",
    "\n",
    "            image_info_Bpredict_permutation['mask'].append(this_mask)\n",
    "            image_info_Bpredict_permutation['iteration'].append(iter)\n",
    "            image_info_Bpredict_permutation['condition'].append(this_cond)\n",
    "            image_info_Bpredict_permutation['pairID'].append(i)\n",
    "            image_info_Bpredict_permutation['preA_indx'].append(preA_indx)\n",
    "            image_info_Bpredict_permutation['preB_indx'].append(preB_indx)\n",
    "            image_info_Bpredict_permutation['preBshuffled_indx'].append(preBshuffled_indx)\n",
    "            image_info_Bpredict_permutation['postB_indx'].append(postB_indx)\n",
    "            image_info_Bpredict_permutation['vioX_indx'].append(vioX_indx)\n",
    "            image_info_Bpredict_permutation['vioY_indx'].append(vioY_indx)\n",
    "            image_info_Bpredict_permutation['preBshuffledvioX_r'].append(preBshuffledvioX)\n",
    "            image_info_Bpredict_permutation['preBshuffledvioY_r'].append(preBshuffledvioY)\n",
    "            image_info_Bpredict_permutation['preBshuffledavgXY_r'].append(preBshuffledavgXY)\n",
    "            image_info_Bpredict_permutation['preApostB_r'].append(preApostB) \n",
    "        \n",
    "        # pull out values for this iteration and correlate\n",
    "        select_data = pd.DataFrame.from_dict(image_info_Bpredict_permutation)\n",
    "        select_data = select_data[(select_data['mask']==this_mask) & (select_data['iteration'] == iter)]\n",
    "        correlation = select_data['preApostB_r'].corr(select_data['preBshuffledavgXY_r'])\n",
    "        \n",
    "        Bpredict_diff_corr_shuffled['mask'].append(this_mask)\n",
    "        Bpredict_diff_corr_shuffled['iteration'].append(iter)\n",
    "        Bpredict_diff_corr_shuffled['BpredictDiff_r'].append(correlation)\n",
    "        Bpredict_diff_corr_shuffled['BpredictDiff_z'].append(np.arctanh(correlation))\n",
    "\n",
    "df999 = pd.DataFrame.from_dict(Bpredict_diff_corr_shuffled)\n",
    "df999.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for each mask and compute z-score\n",
    "\n",
    "# setup dictionary\n",
    "Bpredict_zscore={'mask': [], 'BpredictDiff_observed_fisherz': [], 'shuffled_mean': [],\n",
    "                 'shuffled_std': [], 'BpredictDiff_permutation_zscore': []}\n",
    "\n",
    "# convert to dataframe\n",
    "shuffled_data = pd.DataFrame.from_dict(Bpredict_diff_corr_shuffled)\n",
    "\n",
    "n_subplots = len(mask_list)\n",
    "f, ax = plt.subplots(1, n_subplots, sharey=True, figsize=(n_subplots*5,5)) #figsize=(10,5)\n",
    "for mask in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask]\n",
    "    plot_title = 'mask=%s' %(this_mask)\n",
    "    \n",
    "    # get shuffled data for this mask\n",
    "    select_shuffled_data = shuffled_data[(shuffled_data['mask']==this_mask)]\n",
    "    assert select_shuffled_data.shape[0] == n_iter\n",
    "    shuffled_mean = select_shuffled_data['BpredictDiff_z'].mean()\n",
    "    shuffled_std = select_shuffled_data['BpredictDiff_z'].std(ddof=0) #population std\n",
    "    \n",
    "    # get observed values for this mask\n",
    "    df2 = pd.DataFrame.from_dict(Bpredict_diff_corr)\n",
    "    select_true_data = df2[(df2['mask']==this_mask)]\n",
    "    observed_value = select_true_data['BpredictDiff_z'].values[0]\n",
    "    \n",
    "    # compute z-score\n",
    "    z_score = (observed_value - shuffled_mean)/shuffled_std\n",
    "    print('observed_value:', observed_value, 'z score:', z_score, 'n_iter:', n_iter)\n",
    "    \n",
    "    Bpredict_zscore['mask'].append(this_mask)\n",
    "    Bpredict_zscore['BpredictDiff_observed_fisherz'].append(observed_value)\n",
    "    Bpredict_zscore['shuffled_mean'].append(shuffled_mean)\n",
    "    Bpredict_zscore['shuffled_std'].append(shuffled_std)\n",
    "    Bpredict_zscore['BpredictDiff_permutation_zscore'].append(z_score)\n",
    "    \n",
    "    sns.histplot(data=select_shuffled_data, x=\"BpredictDiff_z\", kde=True, ax=ax[mask], alpha=0.25)\n",
    "    ax[mask].axvline(x=observed_value, color='red')\n",
    "    ax[mask].set_title(plot_title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save subject-specific file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert differentiation dataframe to dictionary before saving\n",
    "avg_differentiation = differentiation.to_dict('list')\n",
    "avg_Bprediction_reward = Bprediction_reward.to_dict('list')\n",
    "\n",
    "# save dictionaries to .npy file\n",
    "outfile = out_dir + '%s_pattern_similarity_analyses' % (sub)\n",
    "print('saving to file: ', outfile)\n",
    "print('')\n",
    "np.savez(outfile, image_info=image_info, pairwise_data=pairwise_data, \n",
    "         differentiation=avg_differentiation, Bprediction_reward=avg_Bprediction_reward,\n",
    "         Bprediction_diff=Bpredict_diff_corr, Bevidence_faces=Bevidence_postfaces_corr, \n",
    "         Bprediction_reward_diff=Bpredict_reward_diff_corr, image_info_differentiation_permutation=image_info_permutation,\n",
    "         differentiation_shuffled_values=differentiation_perm, differentiation_zscores=differentiation_zscore, \n",
    "         image_info_Bpredict_permutation=image_info_Bpredict_permutation, BpredictDiff_corr_shuffled_values=Bpredict_diff_corr_shuffled,\n",
    "         BpredictDiff_corr_zscores=Bpredict_zscore)\n",
    "print('save complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example of how to load saved npz data\n",
    "# infile = out_dir + '/%s_differentiation_prediction.npz' % (sub)\n",
    "# in_data = np.load(infile, allow_pickle=True)\n",
    "# print('loaded dictionaries:', in_data.files)\n",
    "# diff = in_data['differentiation'].item()\n",
    "# example = pd.DataFrame.from_dict(diff)\n",
    "# example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
