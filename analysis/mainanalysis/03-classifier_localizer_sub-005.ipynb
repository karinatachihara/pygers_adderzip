{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier cross-validation\n",
    "\n",
    "### Goals of this script\n",
    "1. import labels (already trimmed but not shifted)\n",
    "2. shift labels to account for hemodynamic lag\n",
    "3. load voxel x TR matrix for ROI(s) of interest\n",
    "4. reshape data (remove all fixation timepoints)\n",
    "5. run classifiers and cross-validate on other localizer run (train on run1, test on run2 and vice-versa)\n",
    "    - model 1: solver='liblinear', class_weight=None\n",
    "    - model 2: solver='liblinear', class_weight='balanced'\n",
    "    - model 3: solver='lbfgs', class_weight=None\n",
    "    - model 4: solver='lbfgs', class_weight='balanced'\n",
    "6. For each subject, save the average prediction probabilities for each classifier as well as the TR-by-TR prediction probabilities.\n",
    "    - classifier=['face_classifier', 'scene_classifier', 'object_classifier']\n",
    "    - trial_type=['face_trials', 'scene_trials', 'object_trials']\n",
    "        - classifier_scores[classifier][mask][run]\n",
    "        - prediction_probabilities[classifier][mask][TR]\n",
    "        - avg_classifier_evidence[trial_type][mask][run][classifier]\n",
    "        - num_voxels[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'sub-005'\n",
    "ses = 'ses-01'\n",
    "task = 'localizer'\n",
    "\n",
    "n_trunc_beginning=5 #Number of volumes to trim from beginning of run\n",
    "n_trunc_end=10 #Number of volumes to trim from end of run\n",
    "ROIs=['bilateral_hippo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn.input_data import NiftiMasker,  MultiNiftiMasker\n",
    "from nilearn.masking import intersect_masks\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "from nilearn.plotting import plot_roi\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io\n",
    "#from mpi4py import MPI\n",
    "import os\n",
    "import pickle \n",
    "import time\n",
    "from scipy.sparse import random\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial.distance import euclidean\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import seaborn as sns\n",
    "\n",
    "# Import machine learning libraries\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, PredefinedSplit\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline \n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The python version is 3.9.10.\n",
      "The scikit-learn version is 1.0.2.\n",
      "The numpy version is 1.20.3.\n",
      "The nilearn version is 0.8.1.\n",
      "The seaborn version is 0.11.2.\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('The python version is {}.'.format(python_version()))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "print('The nilearn version is {}.'.format(nilearn.__version__))\n",
    "print('The seaborn version is {}.'.format(sns.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASKS: localizer\n",
      "LIST OF ALL TASKS: ['localizer']\n",
      "task index: 0\n",
      "\n",
      "bids dir = /jukebox/norman/karina/adderzip_fMRI/adderzip/data/bids/\n",
      "\n",
      "subject dir = /jukebox/norman/karina/adderzip_fMRI/adderzip/data/bids/derivatives/fmriprep/sub-005/ses-01/func/\n",
      "\n",
      "output dir = /jukebox/norman/karina/adderzip_fMRI/adderzip/data/bids/derivatives/firstlevel/sub-005/\n",
      "\n",
      "ROIs = ['bilateral_hippo']\n",
      "Labels = {1: 'Faces', 2: 'Scenes', 3: 'Objects', 0: 'Rest'}\n",
      "number of runs = 3\n",
      "TR = 1.5 seconds\n",
      "TRs per run before trimming = 194\n",
      "5 volumes trimmed from beginning of each run\n",
      "10 volumes trimmed from end of each run\n",
      "TRs per run after trimming = 179\n"
     ]
    }
   ],
   "source": [
    "# Set printing precision\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# load some helper functions\n",
    "sys.path.insert(0, '/jukebox/norman/karina/adderzip_fMRI/adderzip/code/mainanalysis')\n",
    "import adderzip_utils\n",
    "from adderzip_utils import load_adderzip_epi_data, shift_timing, label2TR, mask_data\n",
    "\n",
    "# load some constants\n",
    "from adderzip_utils import adderzip_dir, adderzip_bids_dir, adderzip_label_dict, n_runs, run_names, adderzip_TR, adderzip_hrf_lag, TRs_run\n",
    "\n",
    "print('TASKS:', task)\n",
    "print('LIST OF ALL TASKS:', run_names)\n",
    "task_index = run_names.index(task)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "\n",
    "n_runs_localizer = n_runs[task_index]\n",
    "\n",
    "TRs_run_localizer=TRs_run[task_index]-n_trunc_beginning-n_trunc_end\n",
    "\n",
    "anat_dir=adderzip_bids_dir + 'derivatives/deface/'\n",
    "out_dir= adderzip_bids_dir + 'derivatives/firstlevel/%s/' % sub\n",
    "#mask_fold_other = adderzip_bids_dir + 'derivatives/firstlevel/%s/masks/' % sub\n",
    "mask_fold_hipp = adderzip_bids_dir + 'derivatives/firstlevel/%s/masks/' % sub\n",
    "data_dir='/jukebox/norman/karina/adderzip_fMRI/adderzip/data/mainanalysis/output'\n",
    "\n",
    "#ses0_dir=adderzip_bids_dir + 'derivatives/fmriprep/%s/ses-00/func/' % sub\n",
    "ses1_dir=adderzip_bids_dir + 'derivatives/fmriprep/%s/ses-01/func/' % sub\n",
    "#ses2_dir=adderzip_bids_dir + 'derivatives/fmriprep/%s/ses-02/func/' % sub\n",
    "\n",
    "print('bids dir = %s' % (adderzip_bids_dir))\n",
    "print('')\n",
    "print('subject dir = %s' % (ses1_dir))\n",
    "print('')\n",
    "print('output dir = %s' % (out_dir))\n",
    "print('')\n",
    "print('ROIs = %s' % (ROIs))\n",
    "print('Labels = %s' % (adderzip_label_dict))\n",
    "print('number of runs = %d' % (n_runs_localizer))\n",
    "print('TR = %s seconds' % (adderzip_TR))\n",
    "print('TRs per run before trimming = %s' % (TRs_run[task_index]))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('TRs per run after trimming = %s' % (TRs_run_localizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulus labels  - load truncated stimulus labels and shift labels 4.5 sec (3 TRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svd_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5d4a834bf59c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# take individual run regressor files and concatenate them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_runs_localizer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0min_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msvd_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data/behavioral/regressor/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%s_%s_task-%s_regressor-noshift-trim%dTRs_run-0%d.mat'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trunc_beginning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Load in data from matlab and trim end of labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svd_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# load stimulus labels from regressor file for each run and concatenate\n",
    "# NOTE: Regressor files are already trimmed (beginning only), but not shifted, in Matlab using gen_loc_regressor_0101.m\n",
    "\n",
    "stim_label = [];\n",
    "stim_label_allruns = [];\n",
    "\n",
    "# take individual run regressor files and concatenate them\n",
    "for run in range(1, n_runs_localizer + 1):\n",
    "    in_file = (adderzip_dir + 'data/behavioral/regressor/' + '%s_%s_task-%s_regressor-noshift-trim%dTRs_run-0%d.mat' % (sub, ses, task, n_trunc_beginning, run))\n",
    "    \n",
    "    # Load in data from matlab and trim end of labels\n",
    "    stim_label = scipy.io.loadmat(in_file);\n",
    "    stim_label = np.array(stim_label['regressor']);\n",
    "    stim_label = stim_label[:,:-n_trunc_end] # trim label end\n",
    "\n",
    "    # Store the data\n",
    "    if run == 1:\n",
    "        stim_label_allruns = stim_label;\n",
    "    else:       \n",
    "        stim_label_allruns = np.hstack((stim_label_allruns, stim_label))\n",
    "\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('')\n",
    "print('Trimmed (but not shifted) labels should begin with 10 labels for a stimulus category + 10 labels for rest')\n",
    "print(stim_label_allruns[0,:21])\n",
    "print('Trimmed (but not shifted) labels should end with 10 labels for a stimulus category + 7 trailing zeros ')\n",
    "print(stim_label_allruns[0,-20:])\n",
    "\n",
    "# Plot the labels\n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(stim_label_allruns[0,:], c='orange')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data labels to account for hemodynamic lag\n",
    "shift_size = int(svd_hrf_lag / svd_TR)  # Convert the shift into TRs\n",
    "print('shift by %s TRs' % (shift_size))\n",
    "\n",
    "zero_shift = np.zeros((np.shape(stim_label_allruns)[0],shift_size)) #columns to insert at beginning\n",
    "end_trim = np.shape(stim_label_allruns)[1]-shift_size #trim columns at the end\n",
    "\n",
    "# insert shift columns at beginning and trim columns at end\n",
    "stim_label_allruns_shifted = np.hstack((zero_shift,stim_label_allruns[:,0:end_trim])) \n",
    "\n",
    "# stim_label_allruns_shifted = shift_timing(stim_label_allruns[0,:], shift_size)\n",
    "print('stim_label_allruns has shape: ', np.shape(stim_label_allruns))\n",
    "print('stim_label_allruns_shifted has shape: ', np.shape(stim_label_allruns_shifted))\n",
    "print('')\n",
    "print('Trimmed AND shifted labels should have 3 leading zeros and 4 trailing zeros')\n",
    "print(stim_label_allruns_shifted[0,:15])\n",
    "print(stim_label_allruns_shifted[0,-15:])\n",
    "\n",
    "# Plot the original and shifted labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(stim_label_allruns[0,:], label='original', c='orange')\n",
    "ax.plot(stim_label_allruns_shifted[0,:], label='shifted', c='blue')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR if voxel x TR matrix already exists, load matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load defaced T1 image (merged T1 from fmriprep)\n",
    "t1_file = anat_dir + sub + '_desc-preproc_T1w_defaced.nii.gz'\n",
    "t1_img = image.load_img(t1_file) \n",
    "\n",
    "# Make a function to load the mask data\n",
    "def load_svd_mask(ROI_name, sub):\n",
    "    \"\"\"Load the mask for the svd data \n",
    "    Parameters\n",
    "    ----------\n",
    "    ROI_name: string\n",
    "    sub: string \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    the requested mask\n",
    "    \"\"\"    \n",
    "    # load the mask\n",
    "    if ROI_name == 'bilateral_oc-temp':\n",
    "        mask_fold=mask_fold_other\n",
    "    else:\n",
    "        mask_fold=mask_fold_hipp\n",
    "    maskfile = (mask_fold + sub + \"_%s.nii.gz\" % (ROI_name))\n",
    "    mask = nib.load(maskfile)\n",
    "    print(\"Loaded mask: %s\" % (ROI_name))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load voxel x TR data for each ROI\n",
    "mask_list = ROIs\n",
    "masked_data = []\n",
    "masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "        # load the mask for the corresponding ROI\n",
    "        this_mask = mask_list[mask_counter]\n",
    "        \n",
    "        if this_mask == 'bilateral_oc-temp':\n",
    "            mask_fold=mask_fold_other\n",
    "        else:\n",
    "            mask_fold=mask_fold_hipp\n",
    "        \n",
    "        mask = load_svd_mask(mask_list[mask_counter], sub)\n",
    "        \n",
    "        # plot mask overlayed on subject's T1\n",
    "        plot_roi(mask, bg_img=t1_img, title=this_mask)\n",
    "        \n",
    "        # Load in data from matlab\n",
    "        in_file = (svd_bids_dir + 'v1.2.3_derivatives/firstlevel/%s/masked_epi_data/%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s.mat' % (sub, sub, task, n_trunc_beginning, n_trunc_end, this_mask))\n",
    "        masked_data = scipy.io.loadmat(in_file);\n",
    "        masked_data = np.array(masked_data['data']);\n",
    "        masked_data_all[mask_counter] = masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of the data and plot value of voxel_id across timeseries; make sure data are z-scored \n",
    "num_voxels = [0] * len(mask_list)\n",
    "\n",
    "voxel_id = 100\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print('voxel by TR matrix - shape: ', this_mask, masked_data_all[mask_counter].shape)\n",
    "    num_voxels[mask_counter] = masked_data_all[mask_counter].shape[0] #save number of voxels in each mask\n",
    "    \n",
    "    f, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "    ax.plot(masked_data_all[mask_counter][voxel_id,:])\n",
    "\n",
    "    ax.set_title('Voxel time series, mask = %s, voxel id = %d' % (this_mask, voxel_id))\n",
    "    ax.set_xlabel('TR')\n",
    "    ax.set_ylabel('Voxel Intensity')\n",
    "    \n",
    "print('label list - shape: ', stim_label_allruns_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape labels and data \n",
    "Extract the time points for which we have stimulus labels. For classifier B, we remove all rest TRs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape labels\n",
    "print('Stim_label_allruns_shifted:')\n",
    "print(stim_label_allruns_shifted[0,:])\n",
    "\n",
    "find_nonzeros = np.where(stim_label_allruns_shifted[0,:] > 0)[0] #to double check that numbers line up\n",
    "# print(find_nonzeros)\n",
    "label_index=find_nonzeros\n",
    "\n",
    "# # BE CAREFUL, THIS IS HARDCODED FOR NOW...\n",
    "# label_index_r1 = np.array(range(3,297-4))\n",
    "# label_index_r2 = np.array(range(300,594-4))\n",
    "# label_index = np.hstack((label_index_r1, label_index_r2))\n",
    "# label_index = np.squeeze(label_index)\n",
    "# # print(label_index)\n",
    "# # print(np.shape(label_index))\n",
    "# # print(stim_label_allruns_shifted[0,label_index])\n",
    "\n",
    "reshaped_labels = stim_label_allruns_shifted[:,label_index] #this pulls out columns associated with non-zero labels in the labels file\n",
    "print('reshaped_labels:')\n",
    "print(reshaped_labels[0,:])\n",
    "\n",
    "print('Before reshaping:', np.shape(stim_label_allruns_shifted[0,:]))\n",
    "print('After reshaping:', np.shape(reshaped_labels[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape BOLD data - remove rest timepoints\n",
    "print('mask list:', mask_list)\n",
    "bold_data_reshaped = [0] * len(mask_list)\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "        this_mask = mask_list[mask_counter]\n",
    "        print(this_mask)\n",
    "        \n",
    "        # Pull out the indexes\n",
    "        indexed_data = masked_data_all[mask_counter][:,label_index] #this pulls out columns associated with non-zero labels in the epi data\n",
    "    \n",
    "        print('Original epi shape:', masked_data_all[mask_counter].shape)\n",
    "        print('epi shape after removing zeros:', indexed_data.shape) #this is the bold data with zeros removed\n",
    "\n",
    "        # transpose bold data to make it timepoints x n_voxels\n",
    "        bold_data = np.transpose(indexed_data)\n",
    "        print('timepoints x n_voxels (bold_data):', bold_data.shape)\n",
    "        print('')\n",
    "\n",
    "        bold_data_reshaped[mask_counter] = bold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many labels corresponding to each category? \n",
    "print('Labels = %s' % (svd_label_dict))\n",
    "find_zeros = np.where(reshaped_labels[0,:] == 0)[0] #to double check that numbers line up\n",
    "find_ones = np.where(reshaped_labels[0,:] == 1)[0] #to double check that numbers line up\n",
    "find_twos = np.where(reshaped_labels[0,:] == 2)[0] #to double check that numbers line up\n",
    "find_threes = np.where(reshaped_labels[0,:] == 3)[0] #to double check that numbers line up\n",
    "print(\"number of rest timepoints:\", find_zeros.shape[0])\n",
    "print(\"number of face timepoints:\", find_ones.shape[0])\n",
    "print(\"number of scene timepoints:\", find_twos.shape[0])\n",
    "print(\"number of object timepoints:\", find_threes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4 sets of labels: faces vs. non-faces, scenes vs. non-scenes, objects vs. non-objects, rest vs. non-rest\n",
    "\n",
    "labels = reshaped_labels[0,:]\n",
    "timepoint = reshaped_labels[15,:]\n",
    "labels_timepoints=np.vstack((labels, timepoint))\n",
    "print('labels:', labels.size)\n",
    "# print(labels)\n",
    "print(labels.shape)\n",
    "\n",
    "# faces\n",
    "def numberfunc(x):\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "labels_faces = np.array(list(map(numberfunc, labels[:,])))\n",
    "\n",
    "# scenes\n",
    "def numberfunc(x):\n",
    "    if x == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "labels_scenes = np.array(list(map(numberfunc, labels[:,])))\n",
    "\n",
    "# objects\n",
    "def numberfunc(x):\n",
    "    if x == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "labels_objects = np.array(list(map(numberfunc, labels[:,])))\n",
    "\n",
    "# # rest\n",
    "# def numberfunc(x):\n",
    "#     if x == 0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# labels_rest = np.array(list(map(numberfunc, labels[:,])))\n",
    "\n",
    "# Plot the original and modified labels\n",
    "f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "ax.plot(labels, label='original', c='orange')\n",
    "ax.plot(labels_faces, label='faces', c='blue')\n",
    "ax.plot(labels_scenes, label='scenes', c='red')\n",
    "ax.plot(labels_objects, label='objects', c='green')\n",
    "# ax.plot(labels_rest, label='rest', c='gray')\n",
    "ax.set_ylabel('Stimulus category label')\n",
    "ax.set_xlabel('TR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier B - no rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack the classification code as a function... \n",
    "def decode(X, y, cv_ids, model): \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------\n",
    "    X: np.array, n_stimuli x n_voxels\n",
    "    y: np.array, n_stimuli, \n",
    "    cv_ids: np.array - n_stimuli, \n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    scores\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    models = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    y_actual = []\n",
    "    y_test_index = []\n",
    "    \n",
    "    ps = PredefinedSplit(cv_ids) #split data\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    for train_index, test_index in ps.split():\n",
    "#         print('TRAIN INDEX:', train_index)\n",
    "#         print('TEST INDEX:', test_index)\n",
    "        \n",
    "        # split the data \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # normalize the data \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # fit the model on the training set \n",
    "        model.fit(X_train, y_train)\n",
    "        # calculate the accuracy for the hold out run\n",
    "        score = model.score(X_test, y_test)\n",
    "        # predict class labels for samples in X\n",
    "        prediction = model.predict(X_test)\n",
    "        prediction_prob = model.predict_proba(X_test)\n",
    "#         print('PREDICTION PROBABILITIES:', prediction_prob)\n",
    "        \n",
    "        # save stuff \n",
    "        models.append(model)\n",
    "        scores.append(score)\n",
    "        predictions.append(prediction)\n",
    "        prediction_probs.append(prediction_prob)\n",
    "        y_actual.append(y_test)\n",
    "        y_test_index.append(test_index)\n",
    "        \n",
    "    return models, scores, predictions, prediction_probs, y_actual, y_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare run ids\n",
    "n_runs = n_runs_localizer\n",
    "run_len = labels.size // n_runs\n",
    "run_ids = np.repeat(range(n_runs_localizer), run_len)\n",
    "print('run length:', run_len)\n",
    "print('run IDs:', run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an instance of the model and set parameters\n",
    "model_1 = LogisticRegression(C=1.0, random_state=34, solver='liblinear')\n",
    "model_2 = LogisticRegression(C=1.0, random_state=34, solver='liblinear', class_weight='balanced')\n",
    "model_3 = LogisticRegression(C=1.0, random_state=34, solver='lbfgs')\n",
    "model_4 = LogisticRegression(C=1.0, random_state=34, solver='lbfgs', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list=ROIs\n",
    "category_list = ['faces', 'scenes', 'objects']\n",
    "\n",
    "# classifier accuracy \n",
    "scores_faces = [0] * len(mask_list)\n",
    "scores_scenes = [0] * len(mask_list)\n",
    "scores_objects = [0] * len(mask_list)\n",
    "\n",
    "# binary category prediction\n",
    "predictions_faces = [0] * len(mask_list)\n",
    "predictions_scenes = [0] * len(mask_list)\n",
    "predictions_objects = [0] * len(mask_list)\n",
    "\n",
    "# predict_proba\n",
    "prediction_probs_faces = [0] * len(mask_list)\n",
    "prediction_probs_scenes = [0] * len(mask_list)\n",
    "prediction_probs_objects = [0] * len(mask_list)\n",
    "\n",
    "y_actual_faces = [0] * len(mask_list)\n",
    "y_actual_scenes = [0] * len(mask_list)\n",
    "y_actual_objects = [0] * len(mask_list)\n",
    "\n",
    "y_test_index_faces = [0] * len(mask_list)\n",
    "y_test_index_scenes = [0] * len(mask_list)\n",
    "y_test_index_objects = [0] * len(mask_list)\n",
    "\n",
    "face_trials_pp = [0] * len(mask_list)\n",
    "scene_trials_pp = [0] * len(mask_list)\n",
    "object_trials_pp = [0] * len(mask_list)\n",
    "\n",
    "predict_proba_faces = [0] * len(mask_list)\n",
    "predict_proba_scenes = [0] * len(mask_list)\n",
    "predict_proba_objects = [0] * len(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model_1\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    print('')\n",
    "    print('classifier:', this_category)\n",
    "    if this_category == 'faces':\n",
    "        label_array = labels_faces\n",
    "    elif this_category == 'scenes':\n",
    "        label_array = labels_scenes\n",
    "    elif this_category == 'objects':\n",
    "        label_array = labels_objects\n",
    "    #print('shape - label array:', np.shape(label_array))\n",
    "    \n",
    "    for mask_counter in range(len(mask_list)):\n",
    "            this_mask = mask_list[mask_counter]\n",
    "            #print(this_mask, \"--\", this_category)\n",
    "\n",
    "            models, scores, predictions, prediction_probs, y_actual, y_test_index = decode(X=bold_data_reshaped[mask_counter], y=label_array, cv_ids=run_ids, model=model_1)\n",
    "            print(this_mask,':', scores)\n",
    "        \n",
    "            if this_category == 'faces':\n",
    "                scores_faces[mask_counter] = scores\n",
    "                predictions_faces[mask_counter] = predictions\n",
    "                prediction_probs_faces[mask_counter] = prediction_probs\n",
    "                y_actual_faces = y_actual\n",
    "                y_test_index_faces = y_test_index\n",
    "            elif this_category == 'scenes':\n",
    "                scores_scenes[mask_counter] = scores\n",
    "                predictions_scenes[mask_counter] = predictions\n",
    "                prediction_probs_scenes[mask_counter] = prediction_probs\n",
    "                y_actual_scenes = y_actual\n",
    "                y_test_index_scenes = y_test_index\n",
    "            elif this_category == 'objects':\n",
    "                scores_objects[mask_counter] = scores\n",
    "                predictions_objects[mask_counter] = predictions\n",
    "                prediction_probs_objects[mask_counter] = prediction_probs\n",
    "                y_actual_objects = y_actual\n",
    "                y_test_index_objects = y_test_index\n",
    "\n",
    "print('')\n",
    "print('model 1:', models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First mask\n",
    "mask_index=0\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    if this_category == 'faces':\n",
    "        y_labels_run1 = y_actual_faces[0]\n",
    "        y_labels_run2 = y_actual_faces[1]\n",
    "        all_labels_run1 = labels[y_test_index_faces[0]]\n",
    "        all_labels_run2 = labels[y_test_index_faces[1]]\n",
    "        predict_run1 = predictions_faces[mask_index][0] #this will only grab the first mask\n",
    "        predict_run2 = predictions_faces[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_faces[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_faces[mask_index][1]\n",
    "        title1 = 'Faces vs. Non-faces'\n",
    "        title2 = 'Prediction probabilities - Faces'\n",
    "    elif this_category == 'scenes':\n",
    "        y_labels_run1 = y_actual_scenes[0]\n",
    "        y_labels_run2 = y_actual_scenes[1]\n",
    "        all_labels_run1 = labels[y_test_index_scenes[0]]\n",
    "        all_labels_run2 = labels[y_test_index_scenes[1]]\n",
    "        predict_run1 = predictions_scenes[mask_index][0]\n",
    "        predict_run2 = predictions_scenes[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_scenes[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_scenes[mask_index][1]\n",
    "        title1 = 'Scenes vs. Non-scenes'\n",
    "        title2 = 'Prediction probabilities - Scenes'\n",
    "    elif this_category == 'objects':\n",
    "        y_labels_run1 = y_actual_objects[0]\n",
    "        y_labels_run2 = y_actual_objects[1]\n",
    "        all_labels_run1 = labels[y_test_index_objects[0]]\n",
    "        all_labels_run2 = labels[y_test_index_objects[1]]\n",
    "        predict_run1 = predictions_objects[mask_index][0]\n",
    "        predict_run2 = predictions_objects[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_objects[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_objects[mask_index][1]\n",
    "        title1 = 'Objects vs. Non-objects'\n",
    "        title2 = 'Prediction probabilities - Objects'\n",
    "        \n",
    "    # Train on run 2, test on run 1\n",
    "    f, ax = plt.subplots(2,1, figsize = (20,10))\n",
    "    f.suptitle('Train on run2, test on run1')\n",
    "\n",
    "    ax[0].plot(y_labels_run1, label='actual category', c='black')\n",
    "    ax[0].plot(predict_run1, label='predicted category', c='orange', alpha=0.8)\n",
    "    ax[0].set_ylabel('Stimulus category label')\n",
    "    ax[0].set_xlabel('Trial')\n",
    "    ax[0].set_title(title1)\n",
    "    ax[0].legend()\n",
    "\n",
    "    all_labels = np.unique(all_labels_run1)\n",
    "\n",
    "    for label in all_labels: \n",
    "        mask = label == all_labels_run1\n",
    "        index = np.where(mask)[0]\n",
    "        dummy = np.full(index.shape, 1.05)\n",
    "        \n",
    "        #ax[1].plot(index, all_labels_run1[mask], 'o')\n",
    "        if label == 0: #rest\n",
    "            ax[1].plot(index, dummy, 'o', c='gray')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='rest', c='gray')\n",
    "        elif label == 1: #faces\n",
    "            ax[1].plot(index, dummy, 'o', c='blue')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='faces', c='blue')\n",
    "        elif label == 2: #scenes\n",
    "            ax[1].plot(index, dummy, 'o', c='red')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='scenes', c='red')\n",
    "        elif label == 3: #objects\n",
    "            ax[1].plot(index, dummy, 'o', c='green')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='objects', c='green')\n",
    "            \n",
    "    ax[1].set_ylabel('Prediction probability')\n",
    "    ax[1].set_xlabel('Trial')\n",
    "    ax[1].set_title(title2)\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate average face classifier evidence when actual label is faces(1), scenes(2), or objects(3)\n",
    "# Do the same for scene and object classifiers\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print('')\n",
    "    print(this_mask)\n",
    "\n",
    "    face_index = [0] * n_runs_localizer\n",
    "    scene_index = [0] * n_runs_localizer\n",
    "    object_index = [0] * n_runs_localizer\n",
    "\n",
    "    face_evidence = [0] * n_runs_localizer\n",
    "    scene_evidence = [0] * n_runs_localizer\n",
    "    object_evidence = [0] * n_runs_localizer\n",
    "\n",
    "    face_trials = [0] * n_runs_localizer\n",
    "    scene_trials = [0] * n_runs_localizer\n",
    "    object_trials = [0] * n_runs_localizer\n",
    "\n",
    "    for run in range(0, n_runs_localizer):\n",
    "        print('run:', run+1)\n",
    "        \n",
    "        if run == 0:\n",
    "            these_labels = all_labels_run1\n",
    "        elif run == 1:\n",
    "            these_labels = all_labels_run2\n",
    "            \n",
    "        # locate actual face trials (or scenes, objects)\n",
    "        face_index[run] = np.where(these_labels[:] == 1)[0]\n",
    "        scene_index[run] = np.where(these_labels[:] == 2)[0]\n",
    "        object_index[run] = np.where(these_labels[:] == 3)[0]\n",
    "        \n",
    "        # classifier evidence\n",
    "        face_evidence[run] = prediction_probs_faces[mask_counter][run][:,1]\n",
    "        scene_evidence[run] = prediction_probs_scenes[mask_counter][run][:,1]\n",
    "        object_evidence[run] = prediction_probs_objects[mask_counter][run][:,1]\n",
    "        \n",
    "        for category_counter in range(len(category_list)):\n",
    "            this_category = category_list[category_counter]\n",
    "            \n",
    "            if this_category == 'faces':\n",
    "                face_ev = np.mean(face_evidence[run][face_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][face_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][face_index[run]])\n",
    "                face_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, face_trials[run][:,])\n",
    "            elif this_category == 'scenes':\n",
    "                face_ev = np.mean(face_evidence[run][scene_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][scene_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][scene_index[run]])\n",
    "                scene_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, scene_trials[run][:,])\n",
    "            elif this_category == 'objects':\n",
    "                face_ev = np.mean(face_evidence[run][object_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][object_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][object_index[run]])\n",
    "                object_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, object_trials[run][:,])\n",
    "    \n",
    "    # average classifier evidence [face, scene, object] for each trial type, in each run\n",
    "    face_trials_pp[mask_counter] = face_trials\n",
    "    scene_trials_pp[mask_counter] = scene_trials\n",
    "    object_trials_pp[mask_counter] = object_trials\n",
    "    \n",
    "    # combine predict_proba for both localizer runs\n",
    "    predict_proba_faces[mask_counter] = np.append(prediction_probs_faces[mask_counter][0][:,1], prediction_probs_faces[mask_counter][1][:,1])\n",
    "    predict_proba_scenes[mask_counter] = np.append(prediction_probs_scenes[mask_counter][0][:,1], prediction_probs_scenes[mask_counter][1][:,1])\n",
    "    predict_proba_objects[mask_counter] = np.append(prediction_probs_objects[mask_counter][0][:,1], prediction_probs_objects[mask_counter][1][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrays to dictionaries\n",
    "scores_faces_dict = dict(zip(mask_list, scores_faces))\n",
    "scores_scenes_dict = dict(zip(mask_list, scores_scenes))\n",
    "scores_objects_dict = dict(zip(mask_list, scores_objects))\n",
    "\n",
    "predict_proba_faces_dict = dict(zip(mask_list, predict_proba_faces))\n",
    "predict_proba_scenes_dict = dict(zip(mask_list, predict_proba_scenes))\n",
    "predict_proba_objects_dict = dict(zip(mask_list, predict_proba_objects))\n",
    "\n",
    "num_voxels_dict = dict(zip(mask_list, num_voxels))\n",
    "\n",
    "classifier_list=['face_classifier', 'scene_classifier', 'object_classifier']\n",
    "run_list=['run1', 'run2']\n",
    "\n",
    "# face trials\n",
    "temp_dict = dict(zip(mask_list, face_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "face_trial_classEV = temp_dict\n",
    "\n",
    "# scene trials\n",
    "temp_dict = dict(zip(mask_list, scene_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "scene_trial_classEV = temp_dict\n",
    "\n",
    "# object trials\n",
    "temp_dict = dict(zip(mask_list, object_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "object_trial_classEV = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionaries and save data\n",
    "classifier_scores={'face_classifier': scores_faces_dict, 'scene_classifier': scores_scenes_dict, 'object_classifier': scores_objects_dict}\n",
    "prediction_probabilities={'face_classifier': predict_proba_faces_dict, 'scene_classifier': predict_proba_scenes_dict, 'object_classifier': predict_proba_objects_dict}\n",
    "avg_classifier_evidence={'face_trials': face_trial_classEV, 'scene_trials': scene_trial_classEV, 'object_trials': object_trial_classEV }\n",
    "\n",
    "model1={'classifier_scores': classifier_scores, 'prediction_probabilities': prediction_probabilities,\n",
    "        'avg_classifier_evidence': avg_classifier_evidence, 'num_voxels': num_voxels_dict, \n",
    "        'masks': mask_list, 'labels': labels_timepoints, 'model': models[0]}\n",
    "\n",
    "# save dictionary to .npy file\n",
    "outfile = data_dir + '/%s_localizer_classifierCV-logreg-no_rest-model1' % (sub)\n",
    "print('saving to file: ', outfile)\n",
    "print('')\n",
    "np.save(outfile, model1)\n",
    "print('save complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing how we load \n",
    "# in_file = data_dir + '/%s_localizer_classifierCV-logreg-no_rest-model1.npy' % (sub)\n",
    "# test_data = np.load(in_file, allow_pickle=True)\n",
    "# test_data=test_data.item()\n",
    "# print(test_data['prediction_probabilities']['face_classifier']['bilateral_oc-temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save scores to .mat file\n",
    "# mdict={'face_classifier_scores': scores_faces, 'scene_classifier_scores': scores_scenes, 'object_classifier_scores': scores_objects,\n",
    "#                                  'face_classifier_predict_proba': predict_proba_faces, 'scene_classifier_predict_proba': predict_proba_scenes, 'object_classifier_predict_proba': predict_proba_objects,\n",
    "#                                  'face_trials_classifier_evidence': face_trials_pp, 'scene_trials_classifier_evidence': scene_trials_pp, 'object_trials_classifier_evidence': object_trials_pp,\n",
    "#                                  'num_voxels': num_voxels, 'masks': mask_list, 'labels': labels_timepoints, 'model': models[0]}\n",
    "\n",
    "# mat_out = data_dir + '/%s_localizer_classifierCV-logreg-no_rest-model_1' % (sub)\n",
    "# print('saving to file: ', mat_out)\n",
    "# print('')\n",
    "# scipy.io.savemat(mat_out, mdict)\n",
    "# print('save complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list=ROIs\n",
    "category_list = ['faces', 'scenes', 'objects']\n",
    "\n",
    "# classifier accuracy \n",
    "scores_faces = [0] * len(mask_list)\n",
    "scores_scenes = [0] * len(mask_list)\n",
    "scores_objects = [0] * len(mask_list)\n",
    "\n",
    "# binary category prediction\n",
    "predictions_faces = [0] * len(mask_list)\n",
    "predictions_scenes = [0] * len(mask_list)\n",
    "predictions_objects = [0] * len(mask_list)\n",
    "\n",
    "# predict_proba\n",
    "prediction_probs_faces = [0] * len(mask_list)\n",
    "prediction_probs_scenes = [0] * len(mask_list)\n",
    "prediction_probs_objects = [0] * len(mask_list)\n",
    "\n",
    "y_actual_faces = [0] * len(mask_list)\n",
    "y_actual_scenes = [0] * len(mask_list)\n",
    "y_actual_objects = [0] * len(mask_list)\n",
    "\n",
    "y_test_index_faces = [0] * len(mask_list)\n",
    "y_test_index_scenes = [0] * len(mask_list)\n",
    "y_test_index_objects = [0] * len(mask_list)\n",
    "\n",
    "face_trials_pp = [0] * len(mask_list)\n",
    "scene_trials_pp = [0] * len(mask_list)\n",
    "object_trials_pp = [0] * len(mask_list)\n",
    "\n",
    "predict_proba_faces = [0] * len(mask_list)\n",
    "predict_proba_scenes = [0] * len(mask_list)\n",
    "predict_proba_objects = [0] * len(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model_2\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    print('')\n",
    "    print('classifier:', this_category)\n",
    "    if this_category == 'faces':\n",
    "        label_array = labels_faces\n",
    "    elif this_category == 'scenes':\n",
    "        label_array = labels_scenes\n",
    "    elif this_category == 'objects':\n",
    "        label_array = labels_objects\n",
    "    #print('shape - label array:', np.shape(label_array))\n",
    "    \n",
    "    for mask_counter in range(len(mask_list)):\n",
    "            this_mask = mask_list[mask_counter]\n",
    "            #print(this_mask, \"--\", this_category)\n",
    "\n",
    "            models, scores, predictions, prediction_probs, y_actual, y_test_index = decode(X=bold_data_reshaped[mask_counter], y=label_array, cv_ids=run_ids, model=model_2)\n",
    "            print(this_mask,':', scores)\n",
    "        \n",
    "            if this_category == 'faces':\n",
    "                scores_faces[mask_counter] = scores\n",
    "                predictions_faces[mask_counter] = predictions\n",
    "                prediction_probs_faces[mask_counter] = prediction_probs\n",
    "                y_actual_faces = y_actual\n",
    "                y_test_index_faces = y_test_index\n",
    "            elif this_category == 'scenes':\n",
    "                scores_scenes[mask_counter] = scores\n",
    "                predictions_scenes[mask_counter] = predictions\n",
    "                prediction_probs_scenes[mask_counter] = prediction_probs\n",
    "                y_actual_scenes = y_actual\n",
    "                y_test_index_scenes = y_test_index\n",
    "            elif this_category == 'objects':\n",
    "                scores_objects[mask_counter] = scores\n",
    "                predictions_objects[mask_counter] = predictions\n",
    "                prediction_probs_objects[mask_counter] = prediction_probs\n",
    "                y_actual_objects = y_actual\n",
    "                y_test_index_objects = y_test_index\n",
    "\n",
    "print('')\n",
    "print('model 2:', models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First mask\n",
    "mask_index=0\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    if this_category == 'faces':\n",
    "        y_labels_run1 = y_actual_faces[0]\n",
    "        y_labels_run2 = y_actual_faces[1]\n",
    "        all_labels_run1 = labels[y_test_index_faces[0]]\n",
    "        all_labels_run2 = labels[y_test_index_faces[1]]\n",
    "        predict_run1 = predictions_faces[mask_index][0] #this will only grab the first mask\n",
    "        predict_run2 = predictions_faces[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_faces[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_faces[mask_index][1]\n",
    "        title1 = 'Faces vs. Non-faces'\n",
    "        title2 = 'Prediction probabilities - Faces'\n",
    "    elif this_category == 'scenes':\n",
    "        y_labels_run1 = y_actual_scenes[0]\n",
    "        y_labels_run2 = y_actual_scenes[1]\n",
    "        all_labels_run1 = labels[y_test_index_scenes[0]]\n",
    "        all_labels_run2 = labels[y_test_index_scenes[1]]\n",
    "        predict_run1 = predictions_scenes[mask_index][0]\n",
    "        predict_run2 = predictions_scenes[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_scenes[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_scenes[mask_index][1]\n",
    "        title1 = 'Scenes vs. Non-scenes'\n",
    "        title2 = 'Prediction probabilities - Scenes'\n",
    "    elif this_category == 'objects':\n",
    "        y_labels_run1 = y_actual_objects[0]\n",
    "        y_labels_run2 = y_actual_objects[1]\n",
    "        all_labels_run1 = labels[y_test_index_objects[0]]\n",
    "        all_labels_run2 = labels[y_test_index_objects[1]]\n",
    "        predict_run1 = predictions_objects[mask_index][0]\n",
    "        predict_run2 = predictions_objects[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_objects[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_objects[mask_index][1]\n",
    "        title1 = 'Objects vs. Non-objects'\n",
    "        title2 = 'Prediction probabilities - Objects'\n",
    "        \n",
    "    # Train on run 2, test on run 1\n",
    "    f, ax = plt.subplots(2,1, figsize = (20,10))\n",
    "    f.suptitle('Train on run2, test on run1')\n",
    "\n",
    "    ax[0].plot(y_labels_run1, label='actual category', c='black')\n",
    "    ax[0].plot(predict_run1, label='predicted category', c='orange', alpha=0.8)\n",
    "    ax[0].set_ylabel('Stimulus category label')\n",
    "    ax[0].set_xlabel('Trial')\n",
    "    ax[0].set_title(title1)\n",
    "    ax[0].legend()\n",
    "\n",
    "    all_labels = np.unique(all_labels_run1)\n",
    "\n",
    "    for label in all_labels: \n",
    "        mask = label == all_labels_run1\n",
    "        index = np.where(mask)[0]\n",
    "        dummy = np.full(index.shape, 1.05)\n",
    "        \n",
    "        #ax[1].plot(index, all_labels_run1[mask], 'o')\n",
    "        if label == 0: #rest\n",
    "            ax[1].plot(index, dummy, 'o', c='gray')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='rest', c='gray')\n",
    "        elif label == 1: #faces\n",
    "            ax[1].plot(index, dummy, 'o', c='blue')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='faces', c='blue')\n",
    "        elif label == 2: #scenes\n",
    "            ax[1].plot(index, dummy, 'o', c='red')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='scenes', c='red')\n",
    "        elif label == 3: #objects\n",
    "            ax[1].plot(index, dummy, 'o', c='green')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='objects', c='green')\n",
    "            \n",
    "    ax[1].set_ylabel('Prediction probability')\n",
    "    ax[1].set_xlabel('Trial')\n",
    "    ax[1].set_title(title2)\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate average face classifier evidence when actual label is faces(1), scenes(2), or objects(3)\n",
    "# Do the same for scene and object classifiers\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print('')\n",
    "    print(this_mask)\n",
    "\n",
    "    face_index = [0] * n_runs_localizer\n",
    "    scene_index = [0] * n_runs_localizer\n",
    "    object_index = [0] * n_runs_localizer\n",
    "\n",
    "    face_evidence = [0] * n_runs_localizer\n",
    "    scene_evidence = [0] * n_runs_localizer\n",
    "    object_evidence = [0] * n_runs_localizer\n",
    "\n",
    "    face_trials = [0] * n_runs_localizer\n",
    "    scene_trials = [0] * n_runs_localizer\n",
    "    object_trials = [0] * n_runs_localizer\n",
    "\n",
    "    for run in range(0, n_runs_localizer):\n",
    "        print('run:', run+1)\n",
    "        \n",
    "        if run == 0:\n",
    "            these_labels = all_labels_run1\n",
    "        elif run == 1:\n",
    "            these_labels = all_labels_run2\n",
    "            \n",
    "        # locate actual face trials (or scenes, objects)\n",
    "        face_index[run] = np.where(these_labels[:] == 1)[0]\n",
    "        scene_index[run] = np.where(these_labels[:] == 2)[0]\n",
    "        object_index[run] = np.where(these_labels[:] == 3)[0]\n",
    "        \n",
    "        # classifier evidence\n",
    "        face_evidence[run] = prediction_probs_faces[mask_counter][run][:,1]\n",
    "        scene_evidence[run] = prediction_probs_scenes[mask_counter][run][:,1]\n",
    "        object_evidence[run] = prediction_probs_objects[mask_counter][run][:,1]\n",
    "        \n",
    "        for category_counter in range(len(category_list)):\n",
    "            this_category = category_list[category_counter]\n",
    "            \n",
    "            if this_category == 'faces':\n",
    "                face_ev = np.mean(face_evidence[run][face_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][face_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][face_index[run]])\n",
    "                face_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, face_trials[run][:,])\n",
    "            elif this_category == 'scenes':\n",
    "                face_ev = np.mean(face_evidence[run][scene_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][scene_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][scene_index[run]])\n",
    "                scene_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, scene_trials[run][:,])\n",
    "            elif this_category == 'objects':\n",
    "                face_ev = np.mean(face_evidence[run][object_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][object_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][object_index[run]])\n",
    "                object_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, object_trials[run][:,])\n",
    "    \n",
    "    # average classifier evidence [face, scene, object] for each trial type, in each run\n",
    "    face_trials_pp[mask_counter] = face_trials\n",
    "    scene_trials_pp[mask_counter] = scene_trials\n",
    "    object_trials_pp[mask_counter] = object_trials\n",
    "    \n",
    "    # combine predict_proba for both localizer runs\n",
    "    predict_proba_faces[mask_counter] = np.append(prediction_probs_faces[mask_counter][0][:,1], prediction_probs_faces[mask_counter][1][:,1])\n",
    "    predict_proba_scenes[mask_counter] = np.append(prediction_probs_scenes[mask_counter][0][:,1], prediction_probs_scenes[mask_counter][1][:,1])\n",
    "    predict_proba_objects[mask_counter] = np.append(prediction_probs_objects[mask_counter][0][:,1], prediction_probs_objects[mask_counter][1][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrays to dictionaries\n",
    "scores_faces_dict = dict(zip(mask_list, scores_faces))\n",
    "scores_scenes_dict = dict(zip(mask_list, scores_scenes))\n",
    "scores_objects_dict = dict(zip(mask_list, scores_objects))\n",
    "\n",
    "predict_proba_faces_dict = dict(zip(mask_list, predict_proba_faces))\n",
    "predict_proba_scenes_dict = dict(zip(mask_list, predict_proba_scenes))\n",
    "predict_proba_objects_dict = dict(zip(mask_list, predict_proba_objects))\n",
    "\n",
    "num_voxels_dict = dict(zip(mask_list, num_voxels))\n",
    "\n",
    "classifier_list=['face_classifier', 'scene_classifier', 'object_classifier']\n",
    "run_list=['run1', 'run2']\n",
    "\n",
    "# face trials\n",
    "temp_dict = dict(zip(mask_list, face_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "face_trial_classEV = temp_dict\n",
    "\n",
    "# scene trials\n",
    "temp_dict = dict(zip(mask_list, scene_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "scene_trial_classEV = temp_dict\n",
    "\n",
    "# object trials\n",
    "temp_dict = dict(zip(mask_list, object_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "object_trial_classEV = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionaries and save data\n",
    "classifier_scores={'face_classifier': scores_faces_dict, 'scene_classifier': scores_scenes_dict, 'object_classifier': scores_objects_dict}\n",
    "prediction_probabilities={'face_classifier': predict_proba_faces_dict, 'scene_classifier': predict_proba_scenes_dict, 'object_classifier': predict_proba_objects_dict}\n",
    "avg_classifier_evidence={'face_trials': face_trial_classEV, 'scene_trials': scene_trial_classEV, 'object_trials': object_trial_classEV }\n",
    "\n",
    "model2={'classifier_scores': classifier_scores, 'prediction_probabilities': prediction_probabilities,\n",
    "        'avg_classifier_evidence': avg_classifier_evidence, 'num_voxels': num_voxels_dict, \n",
    "        'masks': mask_list, 'labels': labels_timepoints, 'model': models[0]}\n",
    "\n",
    "# save dictionary to .npy file\n",
    "outfile = data_dir + '/%s_localizer_classifierCV-logreg-no_rest-model2' % (sub)\n",
    "print('saving to file: ', outfile)\n",
    "print('')\n",
    "np.save(outfile, model2)\n",
    "print('save complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list=ROIs\n",
    "category_list = ['faces', 'scenes', 'objects']\n",
    "\n",
    "# classifier accuracy \n",
    "scores_faces = [0] * len(mask_list)\n",
    "scores_scenes = [0] * len(mask_list)\n",
    "scores_objects = [0] * len(mask_list)\n",
    "\n",
    "# binary category prediction\n",
    "predictions_faces = [0] * len(mask_list)\n",
    "predictions_scenes = [0] * len(mask_list)\n",
    "predictions_objects = [0] * len(mask_list)\n",
    "\n",
    "# predict_proba\n",
    "prediction_probs_faces = [0] * len(mask_list)\n",
    "prediction_probs_scenes = [0] * len(mask_list)\n",
    "prediction_probs_objects = [0] * len(mask_list)\n",
    "\n",
    "y_actual_faces = [0] * len(mask_list)\n",
    "y_actual_scenes = [0] * len(mask_list)\n",
    "y_actual_objects = [0] * len(mask_list)\n",
    "\n",
    "y_test_index_faces = [0] * len(mask_list)\n",
    "y_test_index_scenes = [0] * len(mask_list)\n",
    "y_test_index_objects = [0] * len(mask_list)\n",
    "\n",
    "face_trials_pp = [0] * len(mask_list)\n",
    "scene_trials_pp = [0] * len(mask_list)\n",
    "object_trials_pp = [0] * len(mask_list)\n",
    "\n",
    "predict_proba_faces = [0] * len(mask_list)\n",
    "predict_proba_scenes = [0] * len(mask_list)\n",
    "predict_proba_objects = [0] * len(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model_3\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    print('')\n",
    "    print('classifier:', this_category)\n",
    "    if this_category == 'faces':\n",
    "        label_array = labels_faces\n",
    "    elif this_category == 'scenes':\n",
    "        label_array = labels_scenes\n",
    "    elif this_category == 'objects':\n",
    "        label_array = labels_objects\n",
    "    #print('shape - label array:', np.shape(label_array))\n",
    "    \n",
    "    for mask_counter in range(len(mask_list)):\n",
    "            this_mask = mask_list[mask_counter]\n",
    "            #print(this_mask, \"--\", this_category)\n",
    "\n",
    "            models, scores, predictions, prediction_probs, y_actual, y_test_index = decode(X=bold_data_reshaped[mask_counter], y=label_array, cv_ids=run_ids, model=model_3)\n",
    "            print(this_mask,':', scores)\n",
    "        \n",
    "            if this_category == 'faces':\n",
    "                scores_faces[mask_counter] = scores\n",
    "                predictions_faces[mask_counter] = predictions\n",
    "                prediction_probs_faces[mask_counter] = prediction_probs\n",
    "                y_actual_faces = y_actual\n",
    "                y_test_index_faces = y_test_index\n",
    "            elif this_category == 'scenes':\n",
    "                scores_scenes[mask_counter] = scores\n",
    "                predictions_scenes[mask_counter] = predictions\n",
    "                prediction_probs_scenes[mask_counter] = prediction_probs\n",
    "                y_actual_scenes = y_actual\n",
    "                y_test_index_scenes = y_test_index\n",
    "            elif this_category == 'objects':\n",
    "                scores_objects[mask_counter] = scores\n",
    "                predictions_objects[mask_counter] = predictions\n",
    "                prediction_probs_objects[mask_counter] = prediction_probs\n",
    "                y_actual_objects = y_actual\n",
    "                y_test_index_objects = y_test_index\n",
    "\n",
    "print('')\n",
    "print('model 3:', models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First mask\n",
    "mask_index=0\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    if this_category == 'faces':\n",
    "        y_labels_run1 = y_actual_faces[0]\n",
    "        y_labels_run2 = y_actual_faces[1]\n",
    "        all_labels_run1 = labels[y_test_index_faces[0]]\n",
    "        all_labels_run2 = labels[y_test_index_faces[1]]\n",
    "        predict_run1 = predictions_faces[mask_index][0] #this will only grab the first mask\n",
    "        predict_run2 = predictions_faces[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_faces[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_faces[mask_index][1]\n",
    "        title1 = 'Faces vs. Non-faces'\n",
    "        title2 = 'Prediction probabilities - Faces'\n",
    "    elif this_category == 'scenes':\n",
    "        y_labels_run1 = y_actual_scenes[0]\n",
    "        y_labels_run2 = y_actual_scenes[1]\n",
    "        all_labels_run1 = labels[y_test_index_scenes[0]]\n",
    "        all_labels_run2 = labels[y_test_index_scenes[1]]\n",
    "        predict_run1 = predictions_scenes[mask_index][0]\n",
    "        predict_run2 = predictions_scenes[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_scenes[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_scenes[mask_index][1]\n",
    "        title1 = 'Scenes vs. Non-scenes'\n",
    "        title2 = 'Prediction probabilities - Scenes'\n",
    "    elif this_category == 'objects':\n",
    "        y_labels_run1 = y_actual_objects[0]\n",
    "        y_labels_run2 = y_actual_objects[1]\n",
    "        all_labels_run1 = labels[y_test_index_objects[0]]\n",
    "        all_labels_run2 = labels[y_test_index_objects[1]]\n",
    "        predict_run1 = predictions_objects[mask_index][0]\n",
    "        predict_run2 = predictions_objects[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_objects[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_objects[mask_index][1]\n",
    "        title1 = 'Objects vs. Non-objects'\n",
    "        title2 = 'Prediction probabilities - Objects'\n",
    "        \n",
    "    # Train on run 2, test on run 1\n",
    "    f, ax = plt.subplots(2,1, figsize = (20,10))\n",
    "    f.suptitle('Train on run2, test on run1')\n",
    "\n",
    "    ax[0].plot(y_labels_run1, label='actual category', c='black')\n",
    "    ax[0].plot(predict_run1, label='predicted category', c='orange', alpha=0.8)\n",
    "    ax[0].set_ylabel('Stimulus category label')\n",
    "    ax[0].set_xlabel('Trial')\n",
    "    ax[0].set_title(title1)\n",
    "    ax[0].legend()\n",
    "\n",
    "    all_labels = np.unique(all_labels_run1)\n",
    "\n",
    "    for label in all_labels: \n",
    "        mask = label == all_labels_run1\n",
    "        index = np.where(mask)[0]\n",
    "        dummy = np.full(index.shape, 1.05)\n",
    "        \n",
    "        #ax[1].plot(index, all_labels_run1[mask], 'o')\n",
    "        if label == 0: #rest\n",
    "            ax[1].plot(index, dummy, 'o', c='gray')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='rest', c='gray')\n",
    "        elif label == 1: #faces\n",
    "            ax[1].plot(index, dummy, 'o', c='blue')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='faces', c='blue')\n",
    "        elif label == 2: #scenes\n",
    "            ax[1].plot(index, dummy, 'o', c='red')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='scenes', c='red')\n",
    "        elif label == 3: #objects\n",
    "            ax[1].plot(index, dummy, 'o', c='green')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='objects', c='green')\n",
    "            \n",
    "    ax[1].set_ylabel('Prediction probability')\n",
    "    ax[1].set_xlabel('Trial')\n",
    "    ax[1].set_title(title2)\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate average face classifier evidence when actual label is faces(1), scenes(2), or objects(3)\n",
    "# Do the same for scene and object classifiers\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print('')\n",
    "    print(this_mask)\n",
    "\n",
    "    face_index = [0] * n_runs_localizer\n",
    "    scene_index = [0] * n_runs_localizer\n",
    "    object_index = [0] * n_runs_localizer\n",
    "\n",
    "    face_evidence = [0] * n_runs_localizer\n",
    "    scene_evidence = [0] * n_runs_localizer\n",
    "    object_evidence = [0] * n_runs_localizer\n",
    "\n",
    "    face_trials = [0] * n_runs_localizer\n",
    "    scene_trials = [0] * n_runs_localizer\n",
    "    object_trials = [0] * n_runs_localizer\n",
    "\n",
    "    for run in range(0, n_runs_localizer):\n",
    "        print('run:', run+1)\n",
    "        \n",
    "        if run == 0:\n",
    "            these_labels = all_labels_run1\n",
    "        elif run == 1:\n",
    "            these_labels = all_labels_run2\n",
    "            \n",
    "        # locate actual face trials (or scenes, objects)\n",
    "        face_index[run] = np.where(these_labels[:] == 1)[0]\n",
    "        scene_index[run] = np.where(these_labels[:] == 2)[0]\n",
    "        object_index[run] = np.where(these_labels[:] == 3)[0]\n",
    "        \n",
    "        # classifier evidence\n",
    "        face_evidence[run] = prediction_probs_faces[mask_counter][run][:,1]\n",
    "        scene_evidence[run] = prediction_probs_scenes[mask_counter][run][:,1]\n",
    "        object_evidence[run] = prediction_probs_objects[mask_counter][run][:,1]\n",
    "        \n",
    "        for category_counter in range(len(category_list)):\n",
    "            this_category = category_list[category_counter]\n",
    "            \n",
    "            if this_category == 'faces':\n",
    "                face_ev = np.mean(face_evidence[run][face_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][face_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][face_index[run]])\n",
    "                face_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, face_trials[run][:,])\n",
    "            elif this_category == 'scenes':\n",
    "                face_ev = np.mean(face_evidence[run][scene_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][scene_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][scene_index[run]])\n",
    "                scene_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, scene_trials[run][:,])\n",
    "            elif this_category == 'objects':\n",
    "                face_ev = np.mean(face_evidence[run][object_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][object_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][object_index[run]])\n",
    "                object_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, object_trials[run][:,])\n",
    "    \n",
    "    # average classifier evidence [face, scene, object] for each trial type, in each run\n",
    "    face_trials_pp[mask_counter] = face_trials\n",
    "    scene_trials_pp[mask_counter] = scene_trials\n",
    "    object_trials_pp[mask_counter] = object_trials\n",
    "    \n",
    "    # combine predict_proba for both localizer runs\n",
    "    predict_proba_faces[mask_counter] = np.append(prediction_probs_faces[mask_counter][0][:,1], prediction_probs_faces[mask_counter][1][:,1])\n",
    "    predict_proba_scenes[mask_counter] = np.append(prediction_probs_scenes[mask_counter][0][:,1], prediction_probs_scenes[mask_counter][1][:,1])\n",
    "    predict_proba_objects[mask_counter] = np.append(prediction_probs_objects[mask_counter][0][:,1], prediction_probs_objects[mask_counter][1][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrays to dictionaries\n",
    "scores_faces_dict = dict(zip(mask_list, scores_faces))\n",
    "scores_scenes_dict = dict(zip(mask_list, scores_scenes))\n",
    "scores_objects_dict = dict(zip(mask_list, scores_objects))\n",
    "\n",
    "predict_proba_faces_dict = dict(zip(mask_list, predict_proba_faces))\n",
    "predict_proba_scenes_dict = dict(zip(mask_list, predict_proba_scenes))\n",
    "predict_proba_objects_dict = dict(zip(mask_list, predict_proba_objects))\n",
    "\n",
    "num_voxels_dict = dict(zip(mask_list, num_voxels))\n",
    "\n",
    "classifier_list=['face_classifier', 'scene_classifier', 'object_classifier']\n",
    "run_list=['run1', 'run2']\n",
    "\n",
    "# face trials\n",
    "temp_dict = dict(zip(mask_list, face_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "face_trial_classEV = temp_dict\n",
    "\n",
    "# scene trials\n",
    "temp_dict = dict(zip(mask_list, scene_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "scene_trial_classEV = temp_dict\n",
    "\n",
    "# object trials\n",
    "temp_dict = dict(zip(mask_list, object_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "object_trial_classEV = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionaries and save data\n",
    "classifier_scores={'face_classifier': scores_faces_dict, 'scene_classifier': scores_scenes_dict, 'object_classifier': scores_objects_dict}\n",
    "prediction_probabilities={'face_classifier': predict_proba_faces_dict, 'scene_classifier': predict_proba_scenes_dict, 'object_classifier': predict_proba_objects_dict}\n",
    "avg_classifier_evidence={'face_trials': face_trial_classEV, 'scene_trials': scene_trial_classEV, 'object_trials': object_trial_classEV }\n",
    "\n",
    "model3={'classifier_scores': classifier_scores, 'prediction_probabilities': prediction_probabilities,\n",
    "        'avg_classifier_evidence': avg_classifier_evidence, 'num_voxels': num_voxels_dict, \n",
    "        'masks': mask_list, 'labels': labels_timepoints, 'model': models[0]}\n",
    "\n",
    "# save dictionary to .npy file\n",
    "outfile = data_dir + '/%s_localizer_classifierCV-logreg-no_rest-model3' % (sub)\n",
    "print('saving to file: ', outfile)\n",
    "print('')\n",
    "np.save(outfile, model3)\n",
    "print('save complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list=ROIs\n",
    "category_list = ['faces', 'scenes', 'objects']\n",
    "\n",
    "# classifier accuracy \n",
    "scores_faces = [0] * len(mask_list)\n",
    "scores_scenes = [0] * len(mask_list)\n",
    "scores_objects = [0] * len(mask_list)\n",
    "\n",
    "# binary category prediction\n",
    "predictions_faces = [0] * len(mask_list)\n",
    "predictions_scenes = [0] * len(mask_list)\n",
    "predictions_objects = [0] * len(mask_list)\n",
    "\n",
    "# predict_proba\n",
    "prediction_probs_faces = [0] * len(mask_list)\n",
    "prediction_probs_scenes = [0] * len(mask_list)\n",
    "prediction_probs_objects = [0] * len(mask_list)\n",
    "\n",
    "y_actual_faces = [0] * len(mask_list)\n",
    "y_actual_scenes = [0] * len(mask_list)\n",
    "y_actual_objects = [0] * len(mask_list)\n",
    "\n",
    "y_test_index_faces = [0] * len(mask_list)\n",
    "y_test_index_scenes = [0] * len(mask_list)\n",
    "y_test_index_objects = [0] * len(mask_list)\n",
    "\n",
    "face_trials_pp = [0] * len(mask_list)\n",
    "scene_trials_pp = [0] * len(mask_list)\n",
    "object_trials_pp = [0] * len(mask_list)\n",
    "\n",
    "predict_proba_faces = [0] * len(mask_list)\n",
    "predict_proba_scenes = [0] * len(mask_list)\n",
    "predict_proba_objects = [0] * len(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model_4\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    print('')\n",
    "    print('classifier:', this_category)\n",
    "    if this_category == 'faces':\n",
    "        label_array = labels_faces\n",
    "    elif this_category == 'scenes':\n",
    "        label_array = labels_scenes\n",
    "    elif this_category == 'objects':\n",
    "        label_array = labels_objects\n",
    "    #print('shape - label array:', np.shape(label_array))\n",
    "    \n",
    "    for mask_counter in range(len(mask_list)):\n",
    "            this_mask = mask_list[mask_counter]\n",
    "            #print(this_mask, \"--\", this_category)\n",
    "\n",
    "            models, scores, predictions, prediction_probs, y_actual, y_test_index = decode(X=bold_data_reshaped[mask_counter], y=label_array, cv_ids=run_ids, model=model_4)\n",
    "            print(this_mask,':', scores)\n",
    "        \n",
    "            if this_category == 'faces':\n",
    "                scores_faces[mask_counter] = scores\n",
    "                predictions_faces[mask_counter] = predictions\n",
    "                prediction_probs_faces[mask_counter] = prediction_probs\n",
    "                y_actual_faces = y_actual\n",
    "                y_test_index_faces = y_test_index\n",
    "            elif this_category == 'scenes':\n",
    "                scores_scenes[mask_counter] = scores\n",
    "                predictions_scenes[mask_counter] = predictions\n",
    "                prediction_probs_scenes[mask_counter] = prediction_probs\n",
    "                y_actual_scenes = y_actual\n",
    "                y_test_index_scenes = y_test_index\n",
    "            elif this_category == 'objects':\n",
    "                scores_objects[mask_counter] = scores\n",
    "                predictions_objects[mask_counter] = predictions\n",
    "                prediction_probs_objects[mask_counter] = prediction_probs\n",
    "                y_actual_objects = y_actual\n",
    "                y_test_index_objects = y_test_index\n",
    "\n",
    "print('')\n",
    "print('model 4:', models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First mask\n",
    "mask_index=0\n",
    "for category_counter in range(len(category_list)):\n",
    "    this_category = category_list[category_counter]\n",
    "    if this_category == 'faces':\n",
    "        y_labels_run1 = y_actual_faces[0]\n",
    "        y_labels_run2 = y_actual_faces[1]\n",
    "        all_labels_run1 = labels[y_test_index_faces[0]]\n",
    "        all_labels_run2 = labels[y_test_index_faces[1]]\n",
    "        predict_run1 = predictions_faces[mask_index][0] #this will only grab the first mask\n",
    "        predict_run2 = predictions_faces[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_faces[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_faces[mask_index][1]\n",
    "        title1 = 'Faces vs. Non-faces'\n",
    "        title2 = 'Prediction probabilities - Faces'\n",
    "    elif this_category == 'scenes':\n",
    "        y_labels_run1 = y_actual_scenes[0]\n",
    "        y_labels_run2 = y_actual_scenes[1]\n",
    "        all_labels_run1 = labels[y_test_index_scenes[0]]\n",
    "        all_labels_run2 = labels[y_test_index_scenes[1]]\n",
    "        predict_run1 = predictions_scenes[mask_index][0]\n",
    "        predict_run2 = predictions_scenes[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_scenes[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_scenes[mask_index][1]\n",
    "        title1 = 'Scenes vs. Non-scenes'\n",
    "        title2 = 'Prediction probabilities - Scenes'\n",
    "    elif this_category == 'objects':\n",
    "        y_labels_run1 = y_actual_objects[0]\n",
    "        y_labels_run2 = y_actual_objects[1]\n",
    "        all_labels_run1 = labels[y_test_index_objects[0]]\n",
    "        all_labels_run2 = labels[y_test_index_objects[1]]\n",
    "        predict_run1 = predictions_objects[mask_index][0]\n",
    "        predict_run2 = predictions_objects[mask_index][1]\n",
    "        predict_proba_run1 = prediction_probs_objects[mask_index][0]\n",
    "        predict_proba_run2 = prediction_probs_objects[mask_index][1]\n",
    "        title1 = 'Objects vs. Non-objects'\n",
    "        title2 = 'Prediction probabilities - Objects'\n",
    "        \n",
    "    # Train on run 2, test on run 1\n",
    "    f, ax = plt.subplots(2,1, figsize = (20,10))\n",
    "    f.suptitle('Train on run2, test on run1')\n",
    "\n",
    "    ax[0].plot(y_labels_run1, label='actual category', c='black')\n",
    "    ax[0].plot(predict_run1, label='predicted category', c='orange', alpha=0.8)\n",
    "    ax[0].set_ylabel('Stimulus category label')\n",
    "    ax[0].set_xlabel('Trial')\n",
    "    ax[0].set_title(title1)\n",
    "    ax[0].legend()\n",
    "\n",
    "    all_labels = np.unique(all_labels_run1)\n",
    "\n",
    "    for label in all_labels: \n",
    "        mask = label == all_labels_run1\n",
    "        index = np.where(mask)[0]\n",
    "        dummy = np.full(index.shape, 1.05)\n",
    "        \n",
    "        #ax[1].plot(index, all_labels_run1[mask], 'o')\n",
    "        if label == 0: #rest\n",
    "            ax[1].plot(index, dummy, 'o', c='gray')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='rest', c='gray')\n",
    "        elif label == 1: #faces\n",
    "            ax[1].plot(index, dummy, 'o', c='blue')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='faces', c='blue')\n",
    "        elif label == 2: #scenes\n",
    "            ax[1].plot(index, dummy, 'o', c='red')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='scenes', c='red')\n",
    "        elif label == 3: #objects\n",
    "            ax[1].plot(index, dummy, 'o', c='green')\n",
    "            ax[1].plot(predict_proba_run1[:,1], label='objects', c='green')\n",
    "            \n",
    "    ax[1].set_ylabel('Prediction probability')\n",
    "    ax[1].set_xlabel('Trial')\n",
    "    ax[1].set_title(title2)\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate average face classifier evidence when actual label is faces(1), scenes(2), or objects(3)\n",
    "# Do the same for scene and object classifiers\n",
    "\n",
    "for mask_counter in range(len(mask_list)):\n",
    "    this_mask = mask_list[mask_counter]\n",
    "    print('')\n",
    "    print(this_mask)\n",
    "\n",
    "    face_index = [0] * n_runs_localizer\n",
    "    scene_index = [0] * n_runs_localizer\n",
    "    object_index = [0] * n_runs_localizer\n",
    "\n",
    "    face_evidence = [0] * n_runs_localizer\n",
    "    scene_evidence = [0] * n_runs_localizer\n",
    "    object_evidence = [0] * n_runs_localizer\n",
    "\n",
    "    face_trials = [0] * n_runs_localizer\n",
    "    scene_trials = [0] * n_runs_localizer\n",
    "    object_trials = [0] * n_runs_localizer\n",
    "\n",
    "    for run in range(0, n_runs_localizer):\n",
    "        print('run:', run+1)\n",
    "        \n",
    "        if run == 0:\n",
    "            these_labels = all_labels_run1\n",
    "        elif run == 1:\n",
    "            these_labels = all_labels_run2\n",
    "            \n",
    "        # locate actual face trials (or scenes, objects)\n",
    "        face_index[run] = np.where(these_labels[:] == 1)[0]\n",
    "        scene_index[run] = np.where(these_labels[:] == 2)[0]\n",
    "        object_index[run] = np.where(these_labels[:] == 3)[0]\n",
    "        \n",
    "        # classifier evidence\n",
    "        face_evidence[run] = prediction_probs_faces[mask_counter][run][:,1]\n",
    "        scene_evidence[run] = prediction_probs_scenes[mask_counter][run][:,1]\n",
    "        object_evidence[run] = prediction_probs_objects[mask_counter][run][:,1]\n",
    "        \n",
    "        for category_counter in range(len(category_list)):\n",
    "            this_category = category_list[category_counter]\n",
    "            \n",
    "            if this_category == 'faces':\n",
    "                face_ev = np.mean(face_evidence[run][face_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][face_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][face_index[run]])\n",
    "                face_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, face_trials[run][:,])\n",
    "            elif this_category == 'scenes':\n",
    "                face_ev = np.mean(face_evidence[run][scene_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][scene_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][scene_index[run]])\n",
    "                scene_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, scene_trials[run][:,])\n",
    "            elif this_category == 'objects':\n",
    "                face_ev = np.mean(face_evidence[run][object_index[run]])\n",
    "                scene_ev = np.mean(scene_evidence[run][object_index[run]])\n",
    "                object_ev = np.mean(object_evidence[run][object_index[run]])\n",
    "                object_trials[run]=np.hstack((face_ev, scene_ev, object_ev))\n",
    "                print('actual category:', this_category, object_trials[run][:,])\n",
    "    \n",
    "    # average classifier evidence [face, scene, object] for each trial type, in each run\n",
    "    face_trials_pp[mask_counter] = face_trials\n",
    "    scene_trials_pp[mask_counter] = scene_trials\n",
    "    object_trials_pp[mask_counter] = object_trials\n",
    "    \n",
    "    # combine predict_proba for both localizer runs\n",
    "    predict_proba_faces[mask_counter] = np.append(prediction_probs_faces[mask_counter][0][:,1], prediction_probs_faces[mask_counter][1][:,1])\n",
    "    predict_proba_scenes[mask_counter] = np.append(prediction_probs_scenes[mask_counter][0][:,1], prediction_probs_scenes[mask_counter][1][:,1])\n",
    "    predict_proba_objects[mask_counter] = np.append(prediction_probs_objects[mask_counter][0][:,1], prediction_probs_objects[mask_counter][1][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrays to dictionaries\n",
    "scores_faces_dict = dict(zip(mask_list, scores_faces))\n",
    "scores_scenes_dict = dict(zip(mask_list, scores_scenes))\n",
    "scores_objects_dict = dict(zip(mask_list, scores_objects))\n",
    "\n",
    "predict_proba_faces_dict = dict(zip(mask_list, predict_proba_faces))\n",
    "predict_proba_scenes_dict = dict(zip(mask_list, predict_proba_scenes))\n",
    "predict_proba_objects_dict = dict(zip(mask_list, predict_proba_objects))\n",
    "\n",
    "num_voxels_dict = dict(zip(mask_list, num_voxels))\n",
    "\n",
    "classifier_list=['face_classifier', 'scene_classifier', 'object_classifier']\n",
    "run_list=['run1', 'run2']\n",
    "\n",
    "# face trials\n",
    "temp_dict = dict(zip(mask_list, face_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "face_trial_classEV = temp_dict\n",
    "\n",
    "# scene trials\n",
    "temp_dict = dict(zip(mask_list, scene_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "scene_trial_classEV = temp_dict\n",
    "\n",
    "# object trials\n",
    "temp_dict = dict(zip(mask_list, object_trials_pp))\n",
    "# loop through masks\n",
    "for mask_counter in temp_dict:\n",
    "    temp_dict[mask_counter] = dict(zip(run_list, temp_dict[mask_counter]))\n",
    "    # loop through runs\n",
    "    for run in temp_dict[mask_counter]:\n",
    "        temp_dict[mask_counter][run] = dict(zip(classifier_list, temp_dict[mask_counter][run]))\n",
    "object_trial_classEV = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionaries and save data\n",
    "classifier_scores={'face_classifier': scores_faces_dict, 'scene_classifier': scores_scenes_dict, 'object_classifier': scores_objects_dict}\n",
    "prediction_probabilities={'face_classifier': predict_proba_faces_dict, 'scene_classifier': predict_proba_scenes_dict, 'object_classifier': predict_proba_objects_dict}\n",
    "avg_classifier_evidence={'face_trials': face_trial_classEV, 'scene_trials': scene_trial_classEV, 'object_trials': object_trial_classEV }\n",
    "\n",
    "model4={'classifier_scores': classifier_scores, 'prediction_probabilities': prediction_probabilities,\n",
    "        'avg_classifier_evidence': avg_classifier_evidence, 'num_voxels': num_voxels_dict, \n",
    "        'masks': mask_list, 'labels': labels_timepoints, 'model': models[0]}\n",
    "\n",
    "# save dictionary to .npy file\n",
    "outfile = data_dir + '/%s_localizer_classifierCV-logreg-no_rest-model4' % (sub)\n",
    "print('saving to file: ', outfile)\n",
    "print('')\n",
    "np.save(outfile, model4)\n",
    "print('save complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
