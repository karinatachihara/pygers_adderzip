{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from ROIs\n",
    "\n",
    "### Goals of this script\n",
    "1. load normalized BOLD data (from 01-denoise-sesXX_sub-XXX.ipynb)\n",
    "2. apply masks\n",
    "3. save the voxel x TR matrix\n",
    "\n",
    "### For submitting slurm job:\n",
    "- approximate time to run for one subject: 1 hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub='sub-008'\n",
    "n_trunc_beginning=14 #Number of volumes to trim/truncate\n",
    "n_trunc_end=10\n",
    "\n",
    "version='v1'\n",
    "binarization_thresh='75'\n",
    "\n",
    "rsa_ROIs = ['bilateral_hippo','bilateral_oc-temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn.input_data import NiftiMasker,  MultiNiftiMasker\n",
    "from nilearn.masking import intersect_masks\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import os\n",
    "import pickle \n",
    "import time\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline \n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The python version is 3.9.10.\n",
      "The numpy version is 1.20.3.\n",
      "The nilearn version is 0.8.1.\n",
      "The nibabel version is 3.2.1.\n",
      "The seaborn version is 0.11.2.\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('The python version is {}.'.format(python_version()))\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "print('The nilearn version is {}.'.format(nilearn.__version__))\n",
    "print('The nibabel version is {}.'.format(nib.__version__))\n",
    "print('The seaborn version is {}.'.format(sns.__version__))\n",
    "\n",
    "assert python_version()== '3.9.10'\n",
    "assert nilearn.__version__=='0.8.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bids dir = /jukebox/norman/karina/adderzip_fMRI/adderzip/data/bids/\n",
      "\n",
      "output dir = /jukebox/norman/karina/adderzip_fMRI/adderzip/data/bids/derivatives/firstlevel/sub-008/masked_epi_data_v1/threshold-75/\n",
      "\n",
      "ROIs = ['bilateral_hippo', 'bilateral_oc-temp']\n",
      "\n",
      "14 volumes trimmed from beginning of each run\n",
      "10 volumes trimmed from end of each run\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set printing precision\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# load some helper functions\n",
    "sys.path.insert(0, '/jukebox/norman/karina/adderzip_fMRI/adderzip/code/analysis/mainanalysis')\n",
    "import adderzip_utils\n",
    "from adderzip_utils import load_adderzip_stim_labels_localizer, load_adderzip_epi_data, shift_timing, label2TR\n",
    "\n",
    "# load some constants\n",
    "from adderzip_utils import adderzip_dir, adderzip_bids_dir, adderzip_TR, adderzip_hrf_lag, run_names, n_runs, TRs_run, run_order_start\n",
    "\n",
    "shift_size = int(adderzip_hrf_lag / adderzip_TR) # Convert the shift into TRs\n",
    "\n",
    "deriv_dir=adderzip_bids_dir + 'derivatives/'\n",
    "anat_dir=deriv_dir + 'deface/'\n",
    "firstlevel_dir=deriv_dir + 'firstlevel/%s/' % sub\n",
    "out_dir_level1=firstlevel_dir + 'masked_epi_data_%s/' % version\n",
    "out_dir=out_dir_level1 + 'threshold-%s/' % binarization_thresh\n",
    "mask_fold=deriv_dir + 'firstlevel/%s/masks/' % sub\n",
    "\n",
    "print('bids dir = %s' % (adderzip_bids_dir))\n",
    "print('')\n",
    "print('output dir = %s' % (out_dir))\n",
    "print('')\n",
    "print('ROIs = %s' % (rsa_ROIs))\n",
    "print('')\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "\n",
    "# make out_dir if it doesn't exist\n",
    "if os.path.exists(out_dir_level1)==False:\n",
    "    print('making new directory:', out_dir_level1)\n",
    "    os.mkdir(out_dir_level1) \n",
    "if os.path.exists(out_dir)==False:\n",
    "    print('making new directory:', out_dir)\n",
    "    os.mkdir(out_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to load the mask data\n",
    "def load_adderzip_mask(ROI_name, sub):\n",
    "    \"\"\"Load the mask for the adderzip data \n",
    "    Parameters\n",
    "    ----------\n",
    "    ROI_name: string\n",
    "    sub: string \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    the requested mask\n",
    "    \"\"\"    \n",
    "    # load the mask\n",
    "    maskfile = (mask_fold + sub + \"_%s.nii.gz\" % (ROI_name))\n",
    "    mask = nib.load(maskfile)\n",
    "    print(\"Loaded %s mask\" % (ROI_name))\n",
    "    return mask\n",
    "\n",
    "def mask_data(epi_data, mask): \n",
    "    \"\"\"mask the input data with the input mask \n",
    "    Parameters\n",
    "    ----------\n",
    "    epi_data\n",
    "    mask\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    masked data\n",
    "    \"\"\"    \n",
    "    #check that masks and BOLD data match\n",
    "    assert mask.shape==epi_data.shape[:3] \n",
    "    assert mask.header.get_zooms()==epi_data.header.get_zooms()[0:3] #resolution\n",
    "    assert mask.affine.all()==epi_data.affine.all() #check that affines match\n",
    "    print('mask shape:', mask.shape, 'dimensions:', mask.header.get_zooms())\n",
    "    print('mask affine:')\n",
    "    print(mask.affine)\n",
    "    \n",
    "    nifti_masker = NiftiMasker(mask_img=mask)\n",
    "    epi_masked_data = nifti_masker.fit_transform(epi_data);\n",
    "    return epi_masked_data\n",
    "\n",
    "def load_adderzip_masked_data(directory, subject_name, mask_list):\n",
    "    masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "    # Cycle through the masks\n",
    "    for mask_counter in range(len(mask_list)):\n",
    "        # load the mask for the corresponding ROI\n",
    "        this_mask = mask_list[mask_counter]\n",
    "        mask = load_adderzip_mask(mask_list[mask_counter], subject_name)\n",
    "        \n",
    "        # # plot mask overlayed on subject's T1\n",
    "        #plot_roi(mask, bg_img=t1_img, title=this_mask)\n",
    "        \n",
    "        # mask the data \n",
    "        print('extracting masked data for %s' %(this_mask))\n",
    "        epi_masked_data = mask_data(epi_data, mask)\n",
    "        epi_masked_data = np.transpose(epi_masked_data)\n",
    "        \n",
    "        # Check the dimensionality of the data\n",
    "        print('voxel by TR matrix - shape: ', epi_masked_data.shape)\n",
    "        print('')\n",
    "        \n",
    "        masked_data_all[mask_counter] = epi_masked_data\n",
    "        \n",
    "    return masked_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fMRI data and apply masks\n",
    "\n",
    "### LOCALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF TASKS: ['localizer']\n",
      "task index: 0\n",
      "\n",
      "TR = 1.5 seconds\n",
      "14 volumes trimmed from beginning of each run\n",
      "10 volumes trimmed from end of each run\n",
      "\n",
      "Number of localizer runs = 3 and TRs per run = 194\n",
      "TRs per localizer run after trimming = 170\n",
      "\n",
      "available ROIs:  ['bilateral_hippo', 'bilateral_oc-temp']\n"
     ]
    }
   ],
   "source": [
    "execute=1 #1 to run, 0 to skip\n",
    "ses='ses-01'\n",
    "task='localizer'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (adderzip_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epi_data shape:  (94, 115, 101, 508) dimensions: (1.5, 1.5, 1.5, 1.5)\n",
      "task TR number  510\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7ad05d905d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'task TR number '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_runs_task\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mTRs_run_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mepi_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mn_runs_task\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mTRs_run_task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading data from %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepi_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('task TR number ', n_runs_task*TRs_run_task)\n",
    "    \n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_adderzip_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
