{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from ROIs\n",
    "\n",
    "### Goals of this script\n",
    "1. load normalized BOLD data (from 01-denoise-sesXX_sub-XXX.ipynb)\n",
    "2. apply masks\n",
    "3. save the voxel x TR matrix\n",
    "\n",
    "### For submitting slurm job:\n",
    "- approximate time to run for one subject: 1 hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub='sub-005'\n",
    "n_trunc_beginning=5 #Number of volumes to trim/truncate\n",
    "n_trunc_end=10\n",
    "\n",
    "version='v4'\n",
    "binarization_thresh='75'\n",
    "\n",
    "rsa_ROIs = ['bilateral_hippo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn.input_data import NiftiMasker,  MultiNiftiMasker\n",
    "from nilearn.masking import intersect_masks\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import os\n",
    "import pickle \n",
    "import time\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline \n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The python version is 3.9.5.\n",
      "The numpy version is 1.20.3.\n",
      "The nilearn version is 0.8.1.\n",
      "The nibabel version is 3.2.1.\n",
      "The seaborn version is 0.11.2.\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('The python version is {}.'.format(python_version()))\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "print('The nilearn version is {}.'.format(nilearn.__version__))\n",
    "print('The nibabel version is {}.'.format(nib.__version__))\n",
    "print('The seaborn version is {}.'.format(sns.__version__))\n",
    "\n",
    "assert python_version()== '3.9.5'\n",
    "assert nilearn.__version__=='0.8.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set printing precision\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# load some helper functions\n",
    "sys.path.insert(0, '/jukebox/norman/karina/adderzip_fMRI/adderzip/code/analysis/mainanalysis')\n",
    "import adderzip_utils\n",
    "from adderzip_utils import load_adderzip_stim_labels_localizer, load_adderzip_epi_data, shift_timing, label2TR\n",
    "\n",
    "# load some constants\n",
    "from svd_utils import svd_dir, svd_bids_dir, svd_TR, svd_hrf_lag, run_names, n_runs, TRs_run\n",
    "\n",
    "shift_size = int(svd_hrf_lag / svd_TR) # Convert the shift into TRs\n",
    "\n",
    "deriv_dir=svd_bids_dir + 'v1.2.3_derivatives/'\n",
    "anat_dir=deriv_dir + 'deface/'\n",
    "firstlevel_dir=deriv_dir + 'firstlevel/%s/' % sub\n",
    "out_dir_level1=firstlevel_dir + 'masked_epi_data_%s/' % version\n",
    "out_dir=out_dir_level1 + 'threshold-%s/' % binarization_thresh\n",
    "mask_fold=deriv_dir + 'firstlevel/%s/rois_ashs/t1space_%s/threshold-%s/' % (sub,version,binarization_thresh)\n",
    "\n",
    "print('bids dir = %s' % (svd_bids_dir))\n",
    "print('')\n",
    "print('output dir = %s' % (out_dir))\n",
    "print('')\n",
    "print('ROIs = %s' % (rsa_ROIs))\n",
    "print('')\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "\n",
    "# make out_dir if it doesn't exist\n",
    "if os.path.exists(out_dir_level1)==False:\n",
    "    print('making new directory:', out_dir_level1)\n",
    "    os.mkdir(out_dir_level1) \n",
    "if os.path.exists(out_dir)==False:\n",
    "    print('making new directory:', out_dir)\n",
    "    os.mkdir(out_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to load the mask data\n",
    "def load_svd_mask(ROI_name, sub):\n",
    "    \"\"\"Load the mask for the svd data \n",
    "    Parameters\n",
    "    ----------\n",
    "    ROI_name: string\n",
    "    sub: string \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    the requested mask\n",
    "    \"\"\"    \n",
    "    # load the mask\n",
    "    maskfile = (mask_fold + sub + \"_%s.nii.gz\" % (ROI_name))\n",
    "    mask = nib.load(maskfile)\n",
    "    print(\"Loaded %s mask\" % (ROI_name))\n",
    "    return mask\n",
    "\n",
    "def mask_data(epi_data, mask): \n",
    "    \"\"\"mask the input data with the input mask \n",
    "    Parameters\n",
    "    ----------\n",
    "    epi_data\n",
    "    mask\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    masked data\n",
    "    \"\"\"    \n",
    "    #check that masks and BOLD data match\n",
    "    assert mask.shape==epi_data.shape[:3] \n",
    "    assert mask.header.get_zooms()==epi_data.header.get_zooms()[0:3] #resolution\n",
    "    assert mask.affine.all()==epi_data.affine.all() #check that affines match\n",
    "    print('mask shape:', mask.shape, 'dimensions:', mask.header.get_zooms())\n",
    "    print('mask affine:')\n",
    "    print(mask.affine)\n",
    "    \n",
    "    nifti_masker = NiftiMasker(mask_img=mask)\n",
    "    epi_masked_data = nifti_masker.fit_transform(epi_data);\n",
    "    return epi_masked_data\n",
    "\n",
    "def load_svd_masked_data(directory, subject_name, mask_list):\n",
    "    masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "    # Cycle through the masks\n",
    "    for mask_counter in range(len(mask_list)):\n",
    "        # load the mask for the corresponding ROI\n",
    "        this_mask = mask_list[mask_counter]\n",
    "        mask = load_svd_mask(mask_list[mask_counter], subject_name)\n",
    "        \n",
    "        # # plot mask overlayed on subject's T1\n",
    "        #plot_roi(mask, bg_img=t1_img, title=this_mask)\n",
    "        \n",
    "        # mask the data \n",
    "        print('extracting masked data for %s' %(this_mask))\n",
    "        epi_masked_data = mask_data(epi_data, mask)\n",
    "        epi_masked_data = np.transpose(epi_masked_data)\n",
    "        \n",
    "        # Check the dimensionality of the data\n",
    "        print('voxel by TR matrix - shape: ', epi_masked_data.shape)\n",
    "        print('')\n",
    "        \n",
    "        masked_data_all[mask_counter] = epi_masked_data\n",
    "        \n",
    "    return masked_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fMRI data and apply masks\n",
    "\n",
    "### LOCALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=1 #1 to run, 0 to skip\n",
    "ses='ses-00'\n",
    "task='localizer'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STUDY AND POSTSCENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=1 #1 to run, 0 to skip\n",
    "ses='ses-01'\n",
    "task='study'\n",
    "task2='postScenes'\n",
    "task_index = run_names.index(task)\n",
    "task2_index = run_names.index(task2)\n",
    "n_runs_task = n_runs[task_index]\n",
    "n_runs_task2 = n_runs[task2_index]\n",
    "n_runs_total = n_runs_task + n_runs_task2\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "TRs_run_task2=TRs_run[task2_index]-n_trunc_beginning-n_trunc_end\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('task index:', task2_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task, TRs_run_task))\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task2, n_runs_task2, TRs_run[task2_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task2, TRs_run_task2))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_ses-01and02_task-study-and-postscenes_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==(n_runs_task*TRs_run_task)+(n_runs_task2*TRs_run_task2)\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-study-and-postscenes_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % ('study-and-postscenes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POSTSCENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=1 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='postScenes'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    task='postscenes'\n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-01_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-01_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POSTFACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=1 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='postFaces'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    task='postfaces'\n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-01_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-01_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=1 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='reward'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAMILIARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=1 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='familiarization'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:  \n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
